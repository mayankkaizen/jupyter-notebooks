{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: [Speed Up Your Python Program with Concurrency](http://www.pybloggers.com/2019/01/speed-up-your-python-program-with-concurrency/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synchronous Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 275 from http://olympus.realpython.org/dice\n",
      "Downloaded 160 in 45.69248032569885 seconds\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def download_site(url, session):\n",
    "    with session.get(url) as response:\n",
    "        print(f\"Read {len(response.content)} from {url}\")\n",
    "        \n",
    "def download_all_sites(sites):\n",
    "    with requests.session() as session:\n",
    "        for url in sites:\n",
    "            download_site(url, session)\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    sites = [\n",
    "        \"http://www.jython.org\",\n",
    "        \"http://olympus.realpython.org/dice\",\n",
    "    ] * 80\n",
    "\n",
    "start_time = time.time()\n",
    "download_all_sites(sites)\n",
    "duration = time.time() - start_time\n",
    "print(f\"Downloaded {len(sites)} in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 160 in 0.04680013656616211 seconds\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "import threading\n",
    "import time\n",
    "\n",
    "thread_local =  threading.local()\n",
    "\n",
    "def get_session():\n",
    "    if not getattr(thread_loacal, \"session\", None):\n",
    "        thread.local.session = requests.Session()\n",
    "    return thread_local.session\n",
    "\n",
    "def download_site(url):\n",
    "    session = get_session()\n",
    "    with session.get(url) as response:\n",
    "        print(f\"Read {len(response.content)} from {url}\")\n",
    "        \n",
    "def download_all_sites(sites):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers =5) as executor:\n",
    "        executor.map(download_site, sites)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "     sites = [\n",
    "        \"http://www.jython.org\",\n",
    "        \"http://olympus.realpython.org/dice\",\n",
    "    ] * 80\n",
    "\n",
    "start_time = time.time()\n",
    "download_all_sites(sites)\n",
    "duration = time.time() - start_time\n",
    "print(f\"Downloaded {len(sites)} in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `threading` Version\n",
    "\n",
    "When you add threading, the overall structure is the same and you only needed to make a few changes. `download_all_sites()` changed from calling the function once per site to a more complex structure.\n",
    "\n",
    "In this version, you’re creating a `ThreadPoolExecutor`, which seems like a complicated thing. Let’s break that down:      \n",
    "    \n",
    "    ThreadPoolExecutor = Thread + Pool + Executor.\n",
    "    \n",
    "You already know about the `Thread part`. The `Pool` portion is where it starts to get interesting. This object is going to create a pool of threads, each of which can run concurrently. Finally, the `Executor` is the part that’s going to control how and when each of the threads in the pool will run. It will execute the request in the pool. \n",
    "\n",
    "Helpfully, the standard library implements `ThreadPoolExecutor` as a context manager so you can use the `with` syntax to manage creating and freeing the pool of `Threads`.\n",
    "\n",
    "Once you have a `ThreadPoolExecutor`, you can use its handy `.map()` method. This method runs the passed-in function on each of the sites in the list. The great part is that it automatically runs them concurrently using the pool of threads it is managing.\n",
    "\n",
    "The other interesting change in our example is that each thread needs to create its own `requests.Session()` object. When you’re looking at the documentation for `requests`, it’s not necessarily easy to tell, but reading one issue (link omitted), it seems fairly clear that you need a separate `Session` for each thread.\n",
    "\n",
    "This is one of the interesting and difficult issues with threading. Because the operating system is in control of when your task gets interrupted and another task starts, any data that is shared between the threads needs to be protected, or thread-safe. Unfortunately `requests.Session()` is not thread-safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strategy to use here is something called thread local storage. `Threading.local()` creates an object that look like a global but is specific to each individual thread. In your example, this is done with `threadLocal` and `get_session()`.\n",
    "\n",
    "`ThreadLocal` is in the `threading` module to specifically solve this problem. It looks a little odd, but you only want to create one of these objects, not one for each thread. The object itself takes care of separating accesses from different threads to different data.\n",
    "\n",
    "When `get_session()` is called, the session it looks up is specific to the particular thread on which it’s running. So each thread will create a single session the first time it calls `get_session()` and then will simply use that session on each subsequent call throughout its lifetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `asyncio` Version ###\n",
    "\n",
    "**`asyncio` Basics**\n",
    "\n",
    "This will be a simplified version of `asycio`. There are many details that are glossed over here, but it still conveys the idea of how it works.\n",
    "\n",
    "The general concept of `asyncio` is that a single Python object, called the **event loop**, controls how and when each task gets run. The event loop is aware of each task and knows what state it’s in. In reality, there are many states that tasks could be in, but for now let’s imagine a simplified event loop that just has two states.\n",
    "\n",
    "The ready state will indicate that a task has work to do and is ready to be run, and the waiting state means that the task is waiting for some external thing to finish, such as a network operation.\n",
    "\n",
    "Your simplified event loop maintains two lists of tasks, one for each of these states. It selects one of the ready tasks and starts it back to running. That task is in complete control until it cooperatively hands the control back to the event loop.\n",
    "\n",
    "When the running task gives control back to the event loop, the event loop places that task into either the ready or waiting list and then goes through each of the tasks in the waiting list to see if it has become ready by an I/O operation completing. It knows that the tasks in the ready list are still ready because it knows they haven’t run yet.\n",
    "\n",
    "Once all of the tasks have been sorted into the right list again, the event loop picks the next task to run, and the process repeats. Your simplified event loop picks the task that has been waiting the longest and runs that. This process repeats until the event loop is finished.\n",
    "\n",
    "An important point of `asyncio` is that the tasks never give up control without intentionally doing so. They never get interrupted in the middle of an operation. This allows us to share resources a bit more easily in `asyncio` than in `threading`. You don’t have to worry about making your code thread-safe.\n",
    "\n",
    "That’s a high-level view of what’s happening with `asyncio`. If you want more detail, this [StackOverflow answer](https://stackoverflow.com/questions/49005651/how-does-asyncio-actually-work/51116910#51116910) provides some good details if you want to dig deeper.[See the last section of this notebook where SO answer is reproduced].\n",
    "\n",
    "**`async` and `await`**\n",
    "\n",
    "Now let’s talk about two new keywords that were added to Python: `async` and `await`. In light of the discussion above, you can view `await` as the magic that allows the task to hand control back to the event loop. When your code awaits a function call, it’s a signal that the call is likely to be something that takes a while and that the task should give up control.\n",
    "\n",
    "It’s easiest to think of `async` as a flag to Python telling it that the function about to be defined uses `await`. There are some cases where this is not strictly true, like asynchronous generators, but it holds for many cases and gives you a simple model while you’re getting started.\n",
    "\n",
    "One exception to this that you’ll see in the next code is the `async with` statement, which creates a context manager from an object you would normally `await`. While the semantics are a little different, the idea is the same: to flag this context manager as something that can get swapped out.\n",
    "\n",
    "As I’m sure you can imagine, there’s some complexity in managing the interaction between the event loop and the tasks. For developers starting out with `asyncio`, these details aren’t important, but you do need to remember that any function that calls `await` needs to be marked with `async`. You’ll get a syntax error otherwise.\n",
    "\n",
    "\n",
    "The below code is running when executed as a script in command prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1182e2a0dd0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0msites\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"http://www.jython.org\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"http://olympus.realpython.org/dice\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m80\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_all_sites\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msites\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Downloaded {len(sites)} in {duration} seconds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\Miniconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_done_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_run_until_complete_cb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_forever\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnew_task\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancelled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\Miniconda3\\lib\\asyncio\\base_events.py\u001b[0m in \u001b[0;36mrun_forever\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This event loop is already running'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m             raise RuntimeError(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 276 from http://olympus.realpython.org/dice\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n",
      "Read 19210 from http://www.jython.org\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "import aiohttp\n",
    "\n",
    "async def download_site(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        print(\"Read {0} from {1}\".format(response.content_length, url))\n",
    "        \n",
    "async def download_all_sites(sites):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for  url in sites:\n",
    "            task = asyncio.ensure_future(download_site(session, url))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks,return_exceptions = True)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    sites = [\"http://www.jython.org\",\"http://olympus.realpython.org/dice\"] * 80\n",
    "    start_time = time.time()\n",
    "    asyncio.get_event_loop().run_until_complete(download_all_sites(sites))\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Downloaded {len(sites)} in {duration} seconds\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `download_site()`\n",
    "\n",
    "`download_site()` at the top is almost identical to the `threading` version with the exception of the `async` keyword on the function definition line and the `await` keyword when you actually call `session.get()`. You’ll see later why Session can be passed in here rather than using thread-local storage.\n",
    "\n",
    "#### `download_site_from_list()`\n",
    "\n",
    "The next function, `download_site_from_list()`, is fairly straight-forward. While there are still items in the list of sites, it pops one from the list and processes it by calling `download_site()`.\n",
    "\n",
    "Since this function is run concurrently in many tasks, you might be wondering if calling `pop()` on a List is thread-safe. It is not. But all of our `asyncio` tasks are actually running in the same thread so you don’t need to worry about thread safety.\n",
    "\n",
    "Tasks can’t be swapped out in the middle of a statement, which means that you don’t need to worry about a task getting interrupted and leaving the list in a bad state. Because there is no `await` keyword, you know that this statement will not hand control back to the event loop.\n",
    "\n",
    "The next statement, `await download_site(...)`, will hand control back to the event loop, but by that point you know the sites list will be in a good state.\n",
    "\n",
    "Note that, similar to our threading example, if you actually need things like queues in your design, the `asyncio` module provides classes and methods that do those operations but work with an event loop.\n",
    "\n",
    "A slightly more subtle difference is that the `session` object does not need to be created in each task like it was in each thread. Each task uses the same session that was created earlier and passed in. You can get away with this because, again, all tasks are running in the same thread, so you don’t have to worry about thread safety.\n",
    "\n",
    "#### `download_all_sites()`\n",
    "\n",
    "`download_all_sites()` is where you will see the biggest change from the threading example.\n",
    "\n",
    "You can share the session across all tasks, so the session is created here as a context manager.\n",
    "\n",
    "Inside that context manager, it creates a list of tasks using `asyncio.ensure_future()`, which also takes care of starting them. Once all the tasks are created, this function uses `asyncio.wait()` to keep the session context alive until all of the tasks have completed.\n",
    "\n",
    "The threading code does something similar to this, but the details are conveniently handled in the `ThreadPoolExecutor`. There currently is not an `AsyncioPoolExecutor` class.\n",
    "\n",
    "There is one small but important change buried in the details here, however. Remember how we talked about the number of threads to create? It wasn’t obvious in the threading example what the optimal number of threads was.\n",
    "\n",
    "One of the cool advantages of asyncio is that it scales far better than threading. Each task takes far fewer resources and less time to create than a thread, so creating and running more of them works well. This example just creates a separate task for each site to download, which works out quite well.\n",
    "\n",
    "#### `__main__`\n",
    "\n",
    "Finally, the nature of `asyncio` means that you have to start up the event loop and tell it which tasks to run. The `__main__` section at the bottom of the file contains the code to `get_event_loop(`) and then `run_until_complete()`. If nothing else, they’ve done an excellent job in naming those functions.\n",
    "\n",
    "If you’ve updated to Python 3.7, the Python core developers simplified this syntax for you. Instead of the `asyncio.get_event_loop().run_until_complete()` tongue-twister, you can just use `asyncio.run()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `multiprocessing` Version ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "session = None\n",
    "\n",
    "def set_global_session():\n",
    "    global session\n",
    "    if not session:\n",
    "        session = requests.Session()\n",
    "        \n",
    "def download_site(url):\n",
    "    with session.get(url) as response:\n",
    "        name = multiprocessing.current_process().name\n",
    "        print(f\"{name}: Read {len(response.content)} from {url}\")\n",
    "        \n",
    "def download_all_sites(sites):\n",
    "    with multiprocessing.Pool(initializer=set_global_session) as pool:\n",
    "        pool.map(download_site, sites)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    sites = [\n",
    "        \"http://www.jython.org\",\n",
    "        \"http://olympus.realpython.org/dice\",\n",
    "    ] * 80\n",
    "\n",
    "    start_time = time.time()\n",
    "    download_all_sites(sites)\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Downloaded {len(sites)} in {duration} seconds\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `multiprocessing` in a Nutshell\n",
    "\n",
    "Up until this point, all of the examples of concurrency in this article run only on a single CPU or core in your computer. The reasons for this have to do with the current design of CPython and something called the **Global Interpreter Lock**, or **GIL**.\n",
    "\n",
    "This article won’t dive into the hows and whys of the GIL. It’s enough for now to know that the synchronous, threading, and asyncio versions of this example all run on a single CPU.\n",
    "\n",
    "`multiprocessing` in the standard library was designed to break down that barrier and run your code across multiple CPUs. At a high level, it does this by creating a new instance of the Python interpreter to run on each CPU and then farming out part of your program to run on it.\n",
    "\n",
    "As you can imagine, bringing up a separate Python interpreter is not as fast as starting a new thread in the current Python interpreter. It’s a heavyweight operation and comes with some restrictions and difficulties, but for the correct problem, it can make a huge difference.\n",
    "\n",
    "#### `multiprocessing` Code\n",
    "\n",
    "The code has a few small changes from our synchronous version. The first one is in `download_all_sites()`. Instead of simply calling `download_site()` repeatedly, it creates a `multiprocessing.Pool` object and has it map `download_site` to the iterable `sites`. This should look familiar from the `threading` example.\n",
    "\n",
    "What happens here is that the Pool creates a number of separate Python interpreter processes and has each one run the specified function on some of the items in the iterable, which in our case is the list of sites. The communication between the main process and the other processes is handled by the `multiprocessing` module for you.\n",
    "\n",
    "The line that creates Pool is worth your attention. First off, it does not specify how many processes to create in the Pool, although that is an optional parameter. By default, `multiprocessing.Pool()` will determine the number of CPUs in your computer and match that. This is frequently the best answer, and it is in our case.\n",
    "\n",
    "For this problem, increasing the number of processes did not make things faster. It actually slowed things down because the cost for setting up and tearing down all those processes was larger than the benefit of doing the I/O requests in parallel.\n",
    "\n",
    "Next we have the `initializer=set_global_session` part of that call. Remember that each process in our Pool has its own memory space. That means that they cannot share things like a `Session` object. You don’t want to create a new Session each time the function is called, you want to create one for each process.\n",
    "\n",
    "The initializer function parameter is built for just this case. There is not a way to pass a return value back from the initializer to the function called by the process `download_site()`, but you can initialize a global session variable to hold the single session for each process. Because each process has its own memory space, the global for each one will be different.\n",
    "\n",
    "That’s really all there is to it. The rest of the code is quite similar to what you’ve seen before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to Speed Up a CPU-Bound Program\n",
    "\n",
    "Let’s shift gears here a little bit. The examples so far have all dealt with an I/O-bound problem. Now, you’ll look into a CPU-bound problem. As you saw, an I/O-bound problem spends most of its time waiting for external operations, like a network call, to complete. A CPU-bound problem, on the other hand, does few I/O operations, and its overall execution time is a factor of how fast it can process the required data.\n",
    "\n",
    "For the purposes of our example, we’ll use a somewhat silly function to create something that takes a long time to run on the CPU. This function computes the square of each number from 1 to the passed-in value:\n",
    "\n",
    "    def cpu_bound(number):\n",
    "        return sum(i * i for i in range(number))\n",
    "\n",
    "You’ll be passing in large numbers, so this will take a while. Remember, this is just a placeholder for your code that actually does something useful and requires significant processing time, like computing the roots of equations or sorting a large data structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU-Bound  Synchronous Version###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration 5.865610361099243 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def cpu_bound(number):\n",
    "    return sum(i*i for i in range(number))\n",
    "\n",
    "def find_sums(numbers):\n",
    "    for number in numbers:\n",
    "        cpu_bound(number)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    numbers = [5_00_000 + x for x in range(20)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    find_sums(numbers)\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Duration {duration} seconds\")        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code calls `cpu_bound()` 20 times with a different large number each time. It does all of this on a single thread in a single process on a single CPU. The execution timing diagram looks like this:\n",
    "\n",
    "Timing Diagram of an CPU Bound Program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU-Bound `multiprocessing` Version ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def cpu_bound(number):\n",
    "    return sum(i*i for i in range(number))\n",
    "\n",
    "def find_sums(numbers):\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        pool.map(cpu_bound, numbers)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    numbers = [5_00_000 + x for x in range(20)]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    find_sums(numbers)\n",
    "    duration = time.time() - start_time\n",
    "    print(f\"Duration {duration} seconds\")        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A SO POST: \"How does `asyncio` actually work?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Following is from a StackOverflow post \"How does `asyncio` actually work?\"[Link](https://stackoverflow.com/questions/49005651/how-does-asyncio-actually-work/51116910#51116910)\n",
    "\n",
    "Before answering this question we need to understand a few base terms.\n",
    "\n",
    "##### Generators\n",
    "\n",
    "Generators are objects that allow us to suspend the execution of a Python function. User curated generators are implemented using th keyword `yield`. By creating a normal function containing the `yield` keyword, we turn that function into a generator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    yield 1\n",
    "    yield 2\n",
    "    \n",
    "gen = test()\n",
    "next(gen)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8a6233884a6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, calling `next()` on the generator causes the interpreter to load test's frame, and return the `yield`ed value. Calling `next()` again, cause the frame to load again into the interpreter stack, and continue on `yield`ing another value.\n",
    "\n",
    "By the third time `next()` is called, our generator was finished, and `StopIteration` was thrown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Communicating with a generator\n",
    "\n",
    "A less known feature of generators, is the fact that you can communicate with them using two methods: `send()` and `throw()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    val = yield 1\n",
    "    print(val)\n",
    "    yield 2\n",
    "    yield 3\n",
    "    \n",
    "gen =  test()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.send('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-01f8f16164c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-c6e2e87bdb83>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32myield\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32myield\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32myield\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen.throw(Exception())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon calling `gen.send()`, the value is passed as a return value from the `yield` keyword.\n",
    "\n",
    "`gen.throw()` on the other hand allows throwing Exceptions inside generators, with the exception raised at the same spot `yield` was called.\n",
    "\n",
    "##### Returning values from generators\n",
    "\n",
    "Returning a value from a generator, results in the value being put inside the `StopIteration` exception, we can later on recover the value from the exception and use it to our need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test():\n",
    "    yield 1\n",
    "    return 'abc'\n",
    "\n",
    "gen = test()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    next(gen)\n",
    "except StopIteration as exc:\n",
    "    print(exc.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Behold, a new keyword: `yield from`\n",
    "\n",
    "Python 3.4 came with the addition of a new keyword: `yield from`. What that keyword allows us to do, is pass on any `next()`, `send()` and `throw()` into an inner-most nested generator. If the inner generators return a value, it is also the return value of `yield from`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inner():\n",
    "    print((yield 2))\n",
    "    return 3\n",
    "\n",
    "def outer():\n",
    "    yield 1\n",
    "    val = yield from inner()\n",
    "    print(val)\n",
    "    yield 4\n",
    "    \n",
    "gen = outer()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.send('abc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together\n",
    "\n",
    "Upon introducing the new keyword `yield from` in Python 3.4, we were now able to create generators inside generators that just like a tunnel, pass the data back and forth from the inner-most to the outer-most generators. This has spawned a new meaning for generators - *coroutines*\n",
    "\n",
    "**Coroutines** are functions that can be stopped and resumed while being run. In Python, they are defind using the **`async def`** keyword. Much like generators, they too use their own form of `yield from` which is **`await`**. Before `async` and `await` were introduced in Python 3.5, we created coroutines in the exact same way generators were created (with `yield from` instead of `await`).\n",
    "\n",
    "```python\n",
    "async def inner():\n",
    "    return 1\n",
    "    \n",
    "async def outer():\n",
    "    await inner()\n",
    "```\n",
    "\n",
    "Like every iterator or generator that implement the `__iter__()` method, coroutines implement `__await__()` which allows them to continue on every time `await coro` is called.\n",
    "\n",
    "There is a nice [sequence diagram](image to be inserted) inside the [Python docs](url to be inserted) that you should check out. \n",
    "\n",
    "In asyncio, apart from coroutine functions, we have 2 important objects: **tasks** and **futures**.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Futures\n",
    "\n",
    "Futures are objects that have th `__await__()` method implemented, and their job is to hold a certain stage and result. The state can be one of the following:\n",
    "\n",
    "1- PENDING - future does not have any result or exception set.\n",
    "\n",
    "2- CANCELLED - future was cancelled using `fut.cancel()`\n",
    "\n",
    "3-FINISHED - future was finished, either by a result set using `fut.set_result()` or by `fut.set_exception()`\n",
    "\n",
    "Another important feature of `future` objects, is that contain a method called `add_done_callback()`. This method allows functions to be called as soon as the task is done - whether it raised an exception or finished.\n",
    "\n",
    "#### Tasks\n",
    "\n",
    "Task objects are special futures, which wrap around coroutines, and communicate with the inner-most and outer-most coroutines. Every time a coroutine `await`s a future, the future is passed all the way back to the task(just like in `yield from`), and the task receives it.\n",
    "\n",
    "Next, the task binds itself to the future. It does so by calling `add_done_callback()` on the future. From now on, if the future will ever be done, by either being cancelled, passed an exception or Passed a Python object as a result, the task's callback will be called, and it will rise back up to existence.\n",
    "\n",
    "### Asyncio\n",
    "\n",
    "The final burning question we must answer is - how is the IO implemented?\n",
    "\n",
    "Deep inside asyncio, we have an event loop. An event loop of tasks. The event loop's job is to call tasks every time they are ready and coordinate all that effort into one single working machine.\n",
    "\n",
    "The IO part of the event loop is built upon a single crucial function called `select`, which is a blocking function, implemented by the OS underneath, that allows waiting on sockets for incoming or outgoing data. Upon data being received it wakes up, and returns the sockets which received data,  or the sockets whom are ready for writing. \n",
    "\n",
    "When you try to receive or send data over a socket through asyncio, what actually happens below is that the socket is first checked if it has any data that can be immediately read or sent. It its `.send()` buffer is full, or the `.recv()` buffer is empty, the socket is registered to the `select` function (by simply adding it to one of the lists, `rlist` for `recv` and `wlist` for `send`) and the appropriate function `await`s a newly created `future` object, tied to that socket. \n",
    "\n",
    "When all available tasks are waiting for futures, the event loop calls `select` and waits. When the one of the sockets has incoming data, or its `send` buffer drained up, asyncio checks for the future object tied to that socket, and sets it done.\n",
    "\n",
    "Now all the magic happens. The future is set to done, the task that added itself before with `add_done_callback()` rises back to life, and calls `send()` on the coroutine which resumes the innermost coroutine (because of th `await` chain) and you read the newly received data from a nearby buffer it was spilled unto.\n",
    "\n",
    "#### Method chain again, in case of `recv()`:\n",
    "\n",
    "1 - `select.select` waits.\n",
    "\n",
    "2 - A ready socket, with data is returned. \n",
    "\n",
    "3 -  Data from the socket is moved into a buffer.\n",
    "\n",
    "4 - `future.set_result()` is called.\n",
    "\n",
    "5 - Task that added itself with `add_done_callback()` is now woken up.\n",
    "\n",
    "6 - Task calls `.send()` on the coroutine which goes all the way into the innermost coroutine and wakes it up. \n",
    "\n",
    "7 - Data is being read from the buffer and returned to our humble user. \n",
    "\n",
    "In summary, asyncio uses generator capabilities, that allows pausing and resuming functions. It uses `yield from` capabilities that allow passing data back and forth from the innermost generator to the outermost. It uses all of those in order to halt function execution while it is waiting for IO to complete (by using the OS `select` function).\n",
    "\n",
    "And the best of all? While one function is paused, another may run and interleave with delicate fabric, which is asyncio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " caa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
