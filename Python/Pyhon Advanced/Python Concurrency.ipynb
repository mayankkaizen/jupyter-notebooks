{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6070c05",
   "metadata": {},
   "source": [
    "### Python Concurrency\n",
    "\n",
    "Following resources need to be studied - \n",
    "\n",
    " - Effective Python book chapter (have to look for it)\n",
    " - [Python Asyncio: The Complete Guide (SuperFast Python link)](https://superfastpython.com/python-asyncio/)\n",
    " - [Async Python in real life](https://guicommits.com/async-python-in-real-life/)\n",
    " - [Python Concurrency: The Tricky Bits](https://python.hamel.dev/concurrency/)\n",
    " - [\tThreads, processes and concurrency in Python: some thoughts](https://news.ycombinator.com/item?id=2012041&utm_source=pocket_saves)\n",
    " - [Python Concurrency: An Intro to Threads](https://www.blog.pythonlibrary.org/2014/02/24/python-concurrency-an-intro-to-threads/?utm_source=pocket_reader)\n",
    " - [Python Multithreading and Multiprocessing Tutorial](https://www.toptal.com/python/beginners-guide-to-concurrency-and-parallelism-in-python?utm_source=pocket_reader)\n",
    " - [Python: A quick introduction to the concurrent.futures module](https://masnun.com/2016/03/29/python-a-quick-introduction-to-the-concurrent-futures-module.html?utm_source=pocket_saves)\n",
    " - [Python 3.6, A Tale of Two Futures ](https://idolstarastronomer.com/two-futures.html?utm_source=pocket_reader)\n",
    " - [Async IO in Python: A Complete Walkthrough](https://realpython.com/async-io-python/?utm_source=pocket_reader)\n",
    " - [Concurrency with Python: CSP and Coroutines](https://bytes.yingw787.com/posts/2019/02/09/concurrency_with_python_csp_and_coroutines/?utm_source=pocket_reader)\n",
    " - [How to Choose the Right Python Concurrency API(SuperFast Python link)](https://superfastpython.com/python-concurrency-choose-api/) Also check this relevant [Reddit link](https://www.reddit.com/r/Python/comments/wbdtim/how_to_choose_the_right_python_concurrency_api/?utm_source=pocket_saves)\n",
    " - [Async IO in Python: A Complete Walkthrough](http://www.pybloggers.com/2019/01/async-io-in-python-a-complete-walkthrough/?utm_source=pocket_reader)\n",
    " \n",
    "Before you go through any of the above, it is advisable to go through following links as well - \n",
    "\n",
    " - [What is the global interpreter lock (GIL) in CPython?](https://stackoverflow.com/questions/1294382/what-is-the-global-interpreter-lock-gil-in-cpython?utm_source=pocket_reader)\n",
    " - [Multiprocessing vs Threading Python](https://stackoverflow.com/questions/3044580/multiprocessing-vs-threading-python?utm_source=pocket_reader)\n",
    " \n",
    "##### Note \n",
    " \n",
    "Although I didn't go through all the links listed above, after initial exploration I've found that the best resource for learing concurrency and asyncio is the book **Python Concurrency with asyncio** which was repeatedly referenced in SuperFast Python link above. Much of the material in this notebook has been taken from this book. \n",
    "\n",
    "#### CAVEAT \n",
    "\n",
    "Run all the examples through command prompt. Notebook environment affects the execution of example codes leading to erroneous results/errors.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a55743b",
   "metadata": {},
   "source": [
    "#### Process  and Threads\n",
    "\n",
    "A process is an application with dedicated memory for it which other processes can't access. A process always has at least one thread (*main thread*) associated with it. Threads other than main thread are usually called *worker threads*. Each thread is associated with some process. Threads do not have their own memory. They instead share memory of their parent process.\n",
    "\n",
    "**Concurrency** - Running multiple processes concurrently by switching from one process to another is called concurrency. In this model, at any given instant, only one process is effectively being run. \n",
    "\n",
    "**Parallelism** - While concurrency implies that multiple tasks are in process simultaneously, it does not imply that they are running together in parallel. When we say something is running in parallel, we mean not only are there two or more tasks happening concurrently, but they are also executing at the same time. \n",
    "\n",
    "[One must read all the answers in this SO post \"What is the difference between concurrency and parallelism?\"](https://stackoverflow.com/questions/1050222/what-is-the-difference-between-concurrency-and-parallelism?utm_source=pocket_reader)\n",
    "\n",
    "Almost every machine these days is a multi-core processor machine. In a quad-core processor, we can run 4 threadS in parallel. However, if you have single-core processor, parallelism isn't possible. Parallelism (in the sense of multithreading) is not possible with single core processors.\n",
    "\n",
    "**CPU bound tasks vs I/O bound tasks**\n",
    "\n",
    "Note that there are basically two types of tasks our programs perform - \n",
    "\n",
    " - I/O bound tasks such as exchanging data from servers/databases etc\n",
    " - CPU bound tasks such as image processing, mathematical computations etc\n",
    " \n",
    "See this SO link titled [What do the terms CPU bound and I/O means?](https://stackoverflow.com/questions/868568/what-do-the-terms-cpu-bound-and-i-o-bound-mean/33510470#33510470) \n",
    "\n",
    "**Python GIL**\n",
    "\n",
    "Python has GIL (Global Interpreter Lock) which means that at any given instant, only one thread will have control of Interpreter. Python's GIL is intended to serialize access to interpreter internals from different threads. On multi-core systems, it means that multiple threads can't effectively make use of multiple cores. In that sense, Python doesn't offer true parallelism. Using separate processes has no such problems with the GIL, because each process has its own separate GIL.  \n",
    "\n",
    "In following examples, you'll see that multithreading isn't much useful for CPU-bound tasks. The way GIL works, when a thread is waiting on some I/O operation, it doesn't hold GIL captive. It releases GIL so that other threads can make use of it. The I/O operations happen *outside* of Python so they don't control GIL. The same is not true for CPU bound operations performed by pure Python code. However, if your program delegates the CPU intensive tasks to some library written in C or Fortran (such as Numpy), it will release the GIL just like it would in I/O bound operations. [See this](https://stackoverflow.com/questions/29270818/why-is-a-python-i-o-bound-task-not-blocked-by-the-gil)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fb89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async1.py\n"
     ]
    }
   ],
   "source": [
    "#single thread example\n",
    "\n",
    "%%file async1.py\n",
    "\n",
    "import os\n",
    "import threading\n",
    "\n",
    "print(f'python process running with process id: {os.getpid()}')\n",
    "\n",
    "total_t = threading.active_count()\n",
    "thread_n = threading.current_thread().name\n",
    "\n",
    "print(f'python is currently running {total_t} thread(s)')\n",
    "print(f'The current thread is {thread_n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ed5ba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python process running with process id: 7056\n",
      "python is currently running 1 thread(s)\n",
      "The current thread is MainThread\n"
     ]
    }
   ],
   "source": [
    "!python async1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395e494",
   "metadata": {},
   "source": [
    "Processes can also create other threads that share the memory of the main process.\n",
    "These threads can do other work concurrently for us via what is known as *multithreading*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c80c42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async2.py\n"
     ]
    }
   ],
   "source": [
    "%%file async2.py\n",
    "\n",
    "import threading\n",
    "\n",
    "def hello_from_thread():\n",
    "    print(f'Hello from thread {threading.current_thread()}!')\n",
    "    \n",
    "hello_thread = threading.Thread(target=hello_from_thread) #a thread for hello_from_thread\n",
    "hello_thread.start()\n",
    "\n",
    "total_threads = threading.active_count()\n",
    "thread_name = threading.current_thread().name\n",
    "\n",
    "print(f'Python is currently running {total_threads} thread(s)')\n",
    "print(f'The current thread is {thread_name}')\n",
    "\n",
    "hello_thread.join() #join will cause the program to pause until the thread we started completed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "394504a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from thread <Thread(Thread-1, started 6492)>!\n",
      "Python is currently running 1 thread(s)\n",
      "The current thread is MainThread\n"
     ]
    }
   ],
   "source": [
    "!python async2.py\n",
    "\n",
    "#wrong output. See below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae70fa80",
   "metadata": {},
   "source": [
    "I am running script from `async2.py` by emulating shell command within Notebook and I am getting wrong output. I mean output should show that there are 2 threads running. However, if you run the script directly from command shell, you get the correct output. \n",
    "\n",
    "Interestingly, I ran the script twice and there were 2 *different* output -\n",
    "\n",
    "```\n",
    "Hello from thread <Thread(Thread-1, started 7864)>!\n",
    "Python is currently running 2 thread(s)\n",
    "The current thread is MainThread\n",
    "```\n",
    "and \n",
    "\n",
    "```\n",
    "Python is currently running 2 thread(s)\n",
    "Hello from thread <Thread(Thread-1, started 7864)>!\n",
    "The current thread is MainThread\n",
    "```\n",
    "\n",
    "Notice the order of first two lines in each output. This is what is called a *race condition*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453febfb",
   "metadata": {},
   "source": [
    "#### Aside -  Multithreading doesn't always produce expected (faster) results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751dbddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(n):\n",
    "    while n > 0:\n",
    "        n -= 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197c58fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65 µs ± 67.1 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit 2**100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c31e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 4s ± 870 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "count(100000000) \n",
    "count(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829b25b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 3s ± 1.1 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "import threading\n",
    "\n",
    "t1 = threading.Thread(target = count, args = (100000000,))\n",
    "t2 = threading.Thread(target = count, args = (100000000,))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join(), t2.join()\n",
    "\n",
    "\n",
    "#we gained nothing from multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9120fbd",
   "metadata": {},
   "source": [
    "Multithreaded applications are a common way to achieve concurrency in many programming languages. There are a few challenges in utilizing concurrency with threads in Python, however. Multithreading is only useful for I/O-bound work because we are limited by the global interpreter lock, which is discussed elsewhere.\n",
    "\n",
    "Multithreading is not the only way we can achieve concurrency; we can also create multiple processes to do work concurrently for us. This is known as multiprocessing. In multiprocessing, a parent process creates one or more child processes that it manages. It can then distribute work to the child processes.\n",
    "\n",
    "Python gives us the `multiprocessing` module to handle this. The API is similar to that of the threading module. We first create a process with a `target` function. Then, we call its `start` method to execute it and finally its `join` method to wait for it to complete running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6541db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async3.py\n"
     ]
    }
   ],
   "source": [
    "%%file async3.py\n",
    "\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "def hello_from_process():\n",
    "    print(f'Hello from child process {os.getpid()}!')\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    hello_process = multiprocessing.Process(target=hello_from_process)\n",
    "    hello_process.start()\n",
    "    print(f'Hello from parent process {os.getpid()}')\n",
    "    hello_process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a1e61",
   "metadata": {},
   "source": [
    "Output would be - \n",
    "\n",
    "```\n",
    "Hello from parent process 7468\n",
    "Hello from child process 5240!\n",
    "```\n",
    "\n",
    "Question - I don't get why order of output is the way it is. Shouldn't second line come first? How do we know which is parent process and which is child process?\n",
    "\n",
    "**Note**  - I have skipped `requests` based examples which show that multithreading is useful for I/O bound operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a4dfd1",
   "metadata": {},
   "source": [
    "#### `asyncio` and the GIL\n",
    "\n",
    "So far we've used the `multithreading` and `multiprocessing` modules and also examined few cases where they were/weren't useful. We also noted that during I/O operations, Python releases the GIL. \n",
    "\n",
    "`asyncio` exploits the fact that I/O operations release the GIL to give us concurrency, even with only one thread. When we utilize asyncio we create objects called coroutines. A coroutine can be thought of as executing a lightweight thread. Much like we can have multiple threads running at the same time, each with their own concurrent I/O operation, we can have many coroutines running alongside one another. **Coroutines are functions that can be stopped and resumed while being run.**\n",
    "\n",
    "For better understanding of coroutines in the context of `asyncio`, see [How does asyncio actually work?](https://stackoverflow.com/questions/49005651/how-does-asyncio-actually-work/51116910#51116910). This is an amazing SO post.\n",
    "\n",
    "**Sockets**\n",
    "\n",
    "I/O operations are all about sending/receiving data to/from a network. A *socket* is a low-level (OS level) abstraction for sending and receiving data over a network. As such, sockets are blocking by default. That is, when we are waiting for a\n",
    "server to reply with data, we halt our application or block it until we get data to read. Thus, our application stops running any other tasks until we get data from the server, an error happens, or there is a timeout. At the operating system level, we don’t need to do this blocking. Sockets can operate in non-blocking mode. In non-blocking mode, when we write bytes to a socket, we can just fire and forget the write or read, and our application can go on to perform other tasks. Later, we can have the operating system tell us that we received bytes and deal with it at that time. This lets the application do any number of things while we wait for bytes to\n",
    "come back to us. Instead of blocking and waiting for data to come to us, we become more reactive, letting the operating system inform us when there is data for us to act on.\n",
    "\n",
    "In all OSes, there is an underlying `select` function which serve as some sort of notification system. **Select** is a blocking function, implemented by the operating system underneath, that allows waiting on sockets for incoming or outgoing data. Upon receiving data it wakes up, and returns the sockets which received data, or the sockets which are ready for writing. \n",
    "\n",
    "This system keep track of our non-blocking sockets and notify us when they are ready for us to do something with them. This notification system is the basis of how asyncio can achieve concurrency. In asyncio’s model of concurrency, we have only one thread executing Python at any given time. When we hit an I/O operation, we hand it over to our operating system’s event notification system to keep track of it for us. Once we have done this handoff, our Python thread is free to keep running other Python code or add more non-blocking sockets for the OS to keep track of for us.\n",
    "\n",
    "But how do we keep track of which tasks are waiting for I/O as opposed to ones that\n",
    "can just run because they are regular Python code? The answer lies in a construct\n",
    "called an **event loop**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103b925f",
   "metadata": {},
   "source": [
    "[Python docs: Coroutines and Tasks](https://docs.python.org/3/library/asyncio-task.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a909fc",
   "metadata": {},
   "source": [
    "#### `asyncio` - Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8643a9a",
   "metadata": {},
   "source": [
    "Some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a4617d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async4.py\n"
     ]
    }
   ],
   "source": [
    "%%file async4.py\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def inner():\n",
    "    await asyncio.sleep(5)\n",
    "    print(\"running inner\")\n",
    "    return 1\n",
    "\n",
    "async def outer():\n",
    "    print(\"running outer\")\n",
    "    await inner()\n",
    "    print(\"Done\")\n",
    "    \n",
    "asyncio.run(outer())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45cac9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async5.py\n"
     ]
    }
   ],
   "source": [
    "%%file async5.py\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def say_after(delay, what):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(what)\n",
    "\n",
    "async def main():\n",
    "    print(f\"started at {time.strftime('%X')}\")\n",
    "\n",
    "    await say_after(3, 'hello')\n",
    "    await say_after(4, 'world')\n",
    "\n",
    "    print(f\"finished at {time.strftime('%X')}\")\n",
    "\n",
    "asyncio.run(main())\n",
    "\n",
    "#This is merely an example of asyncio, coroutine function and async, await keywords. \n",
    "#This is NOT an example of concurrency. The 2 runs of say_after are not concurrent. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed57ad",
   "metadata": {},
   "source": [
    "Output\n",
    "```\n",
    "started at 11:13:00\n",
    "hello\n",
    "world\n",
    "finished at 11:13:07\n",
    "```\n",
    "\n",
    "Notice the gap of 7 seconds. The lines `await say_after(3, 'world')` and `await say_after(4, 'world')` weren't executed concurrently. They were executed sequentially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aef8443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async6.py\n"
     ]
    }
   ],
   "source": [
    "%%file async6.py\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def say_after(delay, what):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(what)\n",
    "\n",
    "async def main():\n",
    "    task1 = asyncio.create_task(\n",
    "        say_after(3, 'hello'))\n",
    "\n",
    "    task2 = asyncio.create_task(\n",
    "        say_after(4, 'world'))\n",
    "\n",
    "    print(f\"started at {time.strftime('%X')}\")\n",
    "\n",
    "    # Wait until both tasks are completed (should take\n",
    "    # around 2 seconds.)\n",
    "    await task1\n",
    "    await task2\n",
    "\n",
    "    print(f\"finished at {time.strftime('%X')}\")\n",
    "    \n",
    "asyncio.run(main())    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7645d6",
   "metadata": {},
   "source": [
    "Output\n",
    "\n",
    "```\n",
    "started at 11:14:20\n",
    "hello\n",
    "world\n",
    "finished at 11:14:24\n",
    "```\n",
    "\n",
    "Now notice the time-gap of 4 second. Unlike `async5.py`, above we created 2 tasks using `async.create_task()`. Now these tasks are run concurrently. This way, we were able to save 3 seconds.  \n",
    "\n",
    "**Future**\n",
    "\n",
    "A Future represents an eventual result of an asynchronous operation. Not thread-safe.\n",
    "\n",
    "Future is an awaitable object. Coroutines can await on Future objects until they either have a result or an exception set, or until they are cancelled. A Future can be awaited multiple times and the result is same. A `future` is a Python object that contains a single value that you expect to get at some\n",
    "point in the future but may not yet have. Usually, when you create a future, it does\n",
    "not have any value it wraps around because it doesn’t yet exist. In this state, it is con-\n",
    "sidered incomplete, unresolved, or simply not done. Then, once you get a result, you\n",
    "can set the value of the future. This will complete the future; at that time, we can\n",
    "consider it finished and extract the result from the future. \n",
    "\n",
    "**Tasks**\n",
    "\n",
    "Tasks are wrappers around a coroutine that schedule a coroutine to run on the event loop as soon as possible. Tasks are used to run coroutines concurrently in event loops. If a coroutine awaits on a Future, the Task suspends the execution of the coroutine and waits for the completion of the Future. When the Future is done, the execution of the wrapped coroutine resumes. \n",
    "\n",
    "**Awaitables**\n",
    "\n",
    "Anything which can be `await`ed. Coroutines, tasks and futures are awaitables. \n",
    "\n",
    "**The relationship between futures, tasks and coroutines**\n",
    "\n",
    "There is a strong relationship between tasks and futures. In fact, `task` directly inherits from `future`. A `future` can be thought as representing a value that we won’t have for a while. A `task` can be thought as a combination of both a coroutine and a `future`. When we create a `task`, we are creating an empty `future` and running the coroutine. Then, when the coroutine has completed with either an exception or a result, we set\n",
    "the result or exception of the `future`.\n",
    "\n",
    "Given the relationship between futures and tasks, is there a similar relationship between tasks and coroutines? After all, all these types can be used in `await` expressions. The common thread between these is the `Awaitable` abstract base class. This class defines one abstract dunder method `__await__`. We won’t go into the specifics about how to create our own awaitables, but anything that implements the `__await__` method can be used in an `await` expression. Coroutines inherit directly from `Awaitable`, as do `future`s. Tasks then extend futures, which gives us the inheritance diagram shown in figure below - \n",
    "\n",
    "               ---------------\n",
    "               |  Awaitable  |\n",
    "               ---------------\n",
    "                     |\n",
    "                     |\n",
    "           ---------------------       \n",
    "           |                   |\n",
    "     --------------     ----------------\n",
    "     |Coroutines  |     |   Futures    |\n",
    "     --------------     ---------------\n",
    "                               |\n",
    "                        ----------------\n",
    "                        |    Tasks     |\n",
    "                        ----------------\n",
    "\n",
    "Event loops use cooperative scheduling: an event loop runs one Task at a time. While a Task awaits for the completion of a Future, the event loop runs other Tasks, callbacks, or performs IO operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78988499",
   "metadata": {},
   "source": [
    "In example `async6`, we saw concurrency using `asyncio` in action. Although we achieved concurrency in that example, our main code block wasn't doing anything except for waiting. Let us make our code do some more work while it waits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2183ae9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async7.py\n"
     ]
    }
   ],
   "source": [
    "%%file async7.py\n",
    "\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def say_after(delay, what):\n",
    "    await asyncio.sleep(delay)\n",
    "    print(what)\n",
    "\n",
    "async def power2():\n",
    "    print('doing power2')\n",
    "    return 2**100000000\n",
    "\n",
    "async def main():\n",
    "    task1 = asyncio.create_task(say_after(3, 'hello'))\n",
    "    task2 = asyncio.create_task(say_after(4, 'world'))\n",
    "    task3 = asyncio.create_task(power2())\n",
    "\n",
    "    print(f\"started at {time.strftime('%X')}\")\n",
    "\n",
    "    # Wait until both tasks are completed (should take\n",
    "    # around 2 seconds.)\n",
    "    await task3\n",
    "    await task1\n",
    "    await task2\n",
    "\n",
    "    print(f\"finished at {time.strftime('%X')}\")\n",
    "    \n",
    "asyncio.run(main())    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665691e",
   "metadata": {},
   "source": [
    "Output - \n",
    "\n",
    "```\n",
    "started at 11:51:33\n",
    "doing power2\n",
    "hello\n",
    "world\n",
    "finished at 11:51:37\n",
    "```\n",
    "\n",
    "Compare examples of `async6` and `async7`. Both are almost identical except for we added a function returning value of 2\\*\\*100000000 in later example. We saw that `async6` took 3 seconds to complete but all it did was awaiting on results. So we made it do some other work while it waited. You can see that it still took only 3 seconds but while waiting for task1 and task2 to be completed, it calculated 2\\*\\*100000000 for us. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145f13d5",
   "metadata": {},
   "source": [
    "#### Cancelling Tasks\n",
    "\n",
    "Canceling a task is straightforward. Each task object has a method named `cancel`, which we can call whenever we’d like to stop a task. Canceling a task will cause that task to raise a `CancelledError` when we await it, which we can then handle as needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f06be4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async8.py\n"
     ]
    }
   ],
   "source": [
    "#It took me some time to understand that following code is wrongly implemented. See example async8 for correct way\n",
    "\n",
    "import asyncio\n",
    "from asyncio import CancelledError\n",
    "\n",
    "async def longwait(n):\n",
    "    print('doing long wait')\n",
    "    await asyncio.sleep(n)\n",
    "\n",
    "async def main():\n",
    "    long_task = asyncio.create_task(longwait(10))\n",
    "\n",
    "    seconds_elapsed = 0\n",
    "    await long_task\n",
    "    \n",
    "    try:    \n",
    "        while not long_task.done():\n",
    "            print('Task not finished, checking again in a second.')\n",
    "            await asyncio.sleep(1)\n",
    "            seconds_elapsed = seconds_elapsed + 1\n",
    "            if seconds_elapsed == 3:\n",
    "                long_task.cancel()\n",
    "    except CancelledError:\n",
    "        print('Our task was cancelled')\n",
    "    \n",
    "asyncio.run(main())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cac6b9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async8.py\n"
     ]
    }
   ],
   "source": [
    "%%file async8.py\n",
    "\n",
    "import asyncio\n",
    "from asyncio import CancelledError\n",
    "\n",
    "async def longwait(n):\n",
    "    print('doing long wait')\n",
    "    await asyncio.sleep(n)\n",
    "\n",
    "async def main():\n",
    "    long_task = asyncio.create_task(longwait(10))\n",
    "\n",
    "    seconds_elapsed = 0\n",
    "\n",
    "    while not long_task.done():                                      #a, \n",
    "        print('Task not finished, checking again in a second.')      #b\n",
    "        await asyncio.sleep(1)                                       #c\n",
    "        seconds_elapsed = seconds_elapsed + 1\n",
    "        if seconds_elapsed == 5:\n",
    "            long_task.cancel()\n",
    "    try:                                                            #d\n",
    "        await long_task\n",
    "    except CancelledError:\n",
    "        print('Our task was cancelled')\n",
    "\n",
    "asyncio.run(main())\n",
    "\n",
    "#Looking at this code, I was wondering wouldn't `while` clause run completely even before `try` clause is executed? \n",
    "#Because long_task doesn't even start executing until we reach to try clause.\n",
    "#Then I realize my mistake. The thing is 1st a# is executed, then #b and then #c. While waiting on #c, code jumps to #d and\n",
    "#while #d is running, code again jumps to #c to check its status. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5502ed",
   "metadata": {},
   "source": [
    "Something important to note about cancellation is that a `CancelledError` can only be thrown from an await statement. This means that if we call cancel on a task when it is executing plain Python code, that code will run until completion until we\n",
    "hit the next `await` statement (if one exists) and a `CancelledError` can be raised. Call-\n",
    "ing cancel won’t magically stop the task in its tracks; it will only stop the task if you’re\n",
    "currently at an await point or its next await point.\n",
    "\n",
    "#### Setting a timeout and canceling with `wait_for`\n",
    "\n",
    "Checking every second or at some other time interval, and then canceling a task, as we did in the previous example, isn’t the easiest way to handle a timeout.\n",
    "\n",
    "asyncio provides this functionality through a function called `asyncio.wait_for`. This function takes in a coroutine or task object, and a timeout specified in seconds. It then returns a coroutine that we can await. If the task takes more time to complete than the timeout we gave it, a `TimeoutException` will be raised. Once we have reached the timeout threshold, the task will automatically be canceled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45b46bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async9.py\n"
     ]
    }
   ],
   "source": [
    "%%file async9.py\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def longwait(n):\n",
    "    print('doing long wait')\n",
    "    await asyncio.sleep(n)\n",
    "\n",
    "async def main():\n",
    "    long_task = asyncio.create_task(longwait(10))\n",
    "    \n",
    "    try:\n",
    "        result = await asyncio.wait_for(long_task, timeout=1)\n",
    "        print(result)\n",
    "    except asyncio.exceptions.TimeoutError:\n",
    "        print('Got a timeout!')\n",
    "        print(f'Was the task cancelled? {long_task.cancelled()}')\n",
    "\n",
    "asyncio.run(main())    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327567d",
   "metadata": {},
   "source": [
    "Canceling tasks automatically if they take longer than expected is normally a good idea. Otherwise, we may have a coroutine waiting indefinitely, taking up resources that may never be released. However, in certain circumstances we may want to keep\n",
    "our coroutine running. For example, we may want to inform a user that something is taking longer than expected after a certain amount of time but not cancel the task when the timeout is exceeded.\n",
    "\n",
    "To do this we can wrap our task with the `asyncio.shield` function. This function will prevent cancellation of the coroutine we pass in, giving it a “shield,” which cancellation requests then ignore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7bb65fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async10.py\n"
     ]
    }
   ],
   "source": [
    "%%file async10.py\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def longwait(n):\n",
    "    print('doing long wait')\n",
    "    await asyncio.sleep(n)\n",
    "\n",
    "async def main():\n",
    "    long_task = asyncio.create_task(longwait(10))\n",
    "    \n",
    "    try:\n",
    "        result = await asyncio.wait_for(asyncio.shield(long_task), timeout=1)\n",
    "        print(result)\n",
    "    except asyncio.exceptions.TimeoutError:\n",
    "        print('Taking longer than usual. Please wait.')\n",
    "        result  = await long_task   \n",
    "        print(result)               \n",
    "\n",
    "asyncio.run(main())    \n",
    "\n",
    "#why not use the `result` from try block?\n",
    "#maybe coz we tried to print result before it was assigned any value in try block?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa8aae",
   "metadata": {},
   "source": [
    "#### Futures\n",
    "\n",
    "We have already talked a bit about futures. \n",
    "\n",
    "To understand the basics of futures, let’s try creating one, setting its value and extracting that value back out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e373fc76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing async11.py\n"
     ]
    }
   ],
   "source": [
    "%%file async11.py\n",
    "\n",
    "from asyncio import Future\n",
    "my_future = Future()\n",
    "\n",
    "print(f'Is my_future done? {my_future.done()}')\n",
    "\n",
    "my_future.set_result(42)\n",
    "\n",
    "print(f'Is my_future done? {my_future.done()}')\n",
    "print(f'What is the result of my_future? {my_future.result()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb980e",
   "metadata": {},
   "source": [
    "Output - \n",
    "\n",
    "```\n",
    "Is my_future done? False\n",
    "Is my_future done? True\n",
    "What is the result of my_future? 42\n",
    "```\n",
    "\n",
    "Futures can also be used in `await` expressions. If we `await` a `future`, we’re saying\n",
    "“pause until the `future` has a value set that I can work with, and once I have a value,\n",
    "wake up and let me process it.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eea5f284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 2, 3, True]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [1,2,3,0,2,3,0, False, True, []]\n",
    "[result for result in results if result]\n",
    "\n",
    "# funny example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74214fc5",
   "metadata": {},
   "source": [
    "#### Measuring coroutine execution time with decorators\n",
    "\n",
    "Go through the following code carefully - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa8a2bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async_timed.py\n"
     ]
    }
   ],
   "source": [
    "%%file async_timed.py\n",
    "\n",
    "import functools\n",
    "import time\n",
    "\n",
    "def async_timed():\n",
    "    def wrapper(func):\n",
    "        @functools.wraps(func)\n",
    "        async def wrapped(*args, **kwargs):\n",
    "            print(f'starting {func} with args {args} {kwargs}')\n",
    "            start = time.time()\n",
    "            try:\n",
    "                return await func(*args, **kwargs)\n",
    "            finally:\n",
    "                end = time.time()\n",
    "                total = end - start\n",
    "                print(f'finished {func} in {total:.4f} second(s)')\n",
    "        return wrapped\n",
    "    return wrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ff3d8",
   "metadata": {},
   "source": [
    "In this decorator, we create a new coroutine called *wrapped*. This is a wrapper around our original coroutine that takes its arguments, \\*args and \\*\\*kwargs, calls an `await` statement, and then returns the result. We surround that `await` statement with one message when we start running the function and another message when we end running the function, keeping track of the start and end time in much the same way that we did in our earlier start-time and end-time example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bdd51a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async12.py\n"
     ]
    }
   ],
   "source": [
    "%%file async12.py\n",
    "\n",
    "import asyncio\n",
    "from async_timed import async_timed\n",
    "\n",
    "@async_timed()\n",
    "async def delay(delay_seconds: int) -> int:\n",
    "    print(f'sleeping for {delay_seconds} second(s)')\n",
    "    await asyncio.sleep(delay_seconds)\n",
    "    print(f'finished sleeping for {delay_seconds} second(s)')\n",
    "    return delay_seconds\n",
    "\n",
    "@async_timed()\n",
    "async def main():\n",
    "    task_one = asyncio.create_task(delay(2))\n",
    "    task_two = asyncio.create_task(delay(3))\n",
    "    await task_one\n",
    "    await task_two\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c02694",
   "metadata": {},
   "source": [
    "Output - \n",
    "\n",
    "```\n",
    "starting <function main at 0x000000630ED99940> with args () {}\n",
    "starting <function delay at 0x000000630ECD2280> with args (2,) {}\n",
    "sleeping for 2 second(s)\n",
    "starting <function delay at 0x000000630ECD2280> with args (3,) {}\n",
    "sleeping for 3 second(s)\n",
    "finished sleeping for 2 second(s)\n",
    "finished <function delay at 0x000000630ECD2280> in 2.0001 second(s)\n",
    "finished sleeping for 3 second(s)\n",
    "finished <function delay at 0x000000630ECD2280> in 3.0002 second(s)\n",
    "finished <function main at 0x000000630ED99940> in 3.0002 second(s)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d9789",
   "metadata": {},
   "source": [
    "We can see that our two delay calls were both started and finished in roughly 2 and\n",
    "3 seconds, respectively, for a total of 5 seconds. Notice, however, that our main coroutine only took 3 seconds to complete because we were waiting concurrently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eaf4fa1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async13.py\n"
     ]
    }
   ],
   "source": [
    "%%file async13.py\n",
    "\n",
    "import asyncio\n",
    "from async_timed import async_timed\n",
    "\n",
    "@async_timed()\n",
    "async def cpu_bound_work():\n",
    "    counter = 0\n",
    "    for i in range(100000000):\n",
    "        counter = counter + 1\n",
    "    return counter\n",
    "\n",
    "@async_timed()\n",
    "async def main():\n",
    "    task_one = asyncio.create_task(cpu_bound_work())\n",
    "    task_two = asyncio.create_task(cpu_bound_work())\n",
    "\n",
    "    await task_one\n",
    "    await task_two\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea21a56",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "starting <function main at 0x0000006FCB0789D0> with args () {}\n",
    "starting <function cpu_bound_work at 0x0000006FCAFB29D0> with args () {}\n",
    "finished <function cpu_bound_work at 0x0000006FCAFB29D0> in 30.3149 second(s)\n",
    "starting <function cpu_bound_work at 0x0000006FCAFB29D0> with args () {}\n",
    "finished <function cpu_bound_work at 0x0000006FCAFB29D0> in 29.4607 second(s)\n",
    "finished <function main at 0x0000006FCB0789D0> in 59.7776 second(s)\n",
    "```\n",
    "\n",
    "Looking at the output above, we may be tempted to think that there are no drawbacks to making all our code use `async` and `await`. After all, it ends up taking the same amount of time as if we had run things sequentially. However, by doing this we can run into situations where our application’s performance can degrade. This is especially true when we have other coroutines or tasks that have `await` expressions. Consider creating two CPU-bound tasks alongside a long-running task, such as our `delay` coroutine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b7f92cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing async14.py\n"
     ]
    }
   ],
   "source": [
    "%%file async14.py\n",
    "\n",
    "import asyncio\n",
    "from async_timed import async_timed\n",
    "\n",
    "async def delay(delay_seconds: int) -> int:\n",
    "    print(f'sleeping for {delay_seconds} second(s)')\n",
    "    await asyncio.sleep(delay_seconds)\n",
    "    print(f'finished sleeping for {delay_seconds} second(s)')\n",
    "\n",
    "@async_timed()\n",
    "async def cpu_bound_work():\n",
    "    counter = 0\n",
    "    for i in range(100000000):\n",
    "        counter = counter + 1\n",
    "    return counter\n",
    "\n",
    "@async_timed()\n",
    "async def main():\n",
    "    task_one = asyncio.create_task(cpu_bound_work())\n",
    "    task_two = asyncio.create_task(cpu_bound_work())\n",
    "\n",
    "    delay_task = asyncio.create_task(delay(4))\n",
    "    await task_one\n",
    "    await task_two\n",
    "    await delay_task\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa729c94",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "starting <function main at 0x00000079ABC09A60> with args () {}\n",
    "starting <function cpu_bound_work at 0x00000079ABC09940> with args () {}\n",
    "finished <function cpu_bound_work at 0x00000079ABC09940> in 32.0007 second(s)\n",
    "starting <function cpu_bound_work at 0x00000079ABC09940> with args () {}\n",
    "finished <function cpu_bound_work at 0x00000079ABC09940> in 30.4292 second(s)\n",
    "sleeping for 4 second(s)\n",
    "finished sleeping for 4 second(s)\n",
    "finished <function main at 0x00000079ABC09A60> in 66.4471 second(s)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81447082",
   "metadata": {},
   "source": [
    "Running the preceding code, we might expect to take the same amount of time as in listing `async13.py`. After all, won’t delay_task run concurrently alongside the CPU-bound work? In this instance it won’t because we create the two CPU-bound tasks first, which, in effect, blocks the event loop from running anything else. This means the runtime of our application will be the sum of time it took for our two `cpu_bound_work` tasks to finish plus the 4 seconds that our delay task took.\n",
    "\n",
    "If we need to perform CPU-bound work and still want to use `async / await` syntax, we can do so. To do this we’ll still need to use multiprocessing, and we need to tell asyncio to run our tasks in a *process pool*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43760500",
   "metadata": {},
   "source": [
    "#### Running blocking APIs\n",
    "\n",
    "We may also be tempted to use our existing libraries for I/O-bound operations by wrapping them in coroutines. However, this will generate the same issues that we saw with CPU-bound operations. These APIs block the main thread. Therefore, when we\n",
    "run a blocking API call inside a coroutine, we’re blocking the event loop thread itself, meaning that we stop any other coroutines or tasks from executing. Examples of blocking API calls include libraries such as `requests`, or `time.sleep`. Generally, any function that performs I/O that is not a coroutine or performs time-consuming CPU\n",
    "operations can be considered blocking.\n",
    "\n",
    "As an example, let’s try getting the status code of www.example.com three times\n",
    "concurrently, using the `requests` library. When we run this, since we’re running concurrently we’ll be expecting this application to finish in about the length of time necessary to get the status code once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f2175cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing async15.py\n"
     ]
    }
   ],
   "source": [
    "%%file async15.py\n",
    "\n",
    "import asyncio\n",
    "import requests\n",
    "from async_timed import async_timed\n",
    "\n",
    "@async_timed()\n",
    "async def get_example_status():\n",
    "    return requests.get('http://www.example.com').status_code\n",
    "\n",
    "@async_timed()\n",
    "async def main():\n",
    "    task_1 = asyncio.create_task(get_example_status())\n",
    "    task_2 = asyncio.create_task(get_example_status())\n",
    "    task_3 = asyncio.create_task(get_example_status())\n",
    "    await task_1\n",
    "    await task_2\n",
    "    await task_3\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59945d3c",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "starting <function main at 0x000000F0A2D661F0> with args () {}\n",
    "starting <function get_example_status at 0x000000F0A2D660D0> with args () {}\n",
    "finished <function get_example_status at 0x000000F0A2D660D0> in 0.9063 second(s)\n",
    "starting <function get_example_status at 0x000000F0A2D660D0> with args () {}\n",
    "finished <function get_example_status at 0x000000F0A2D660D0> in 3.4065 second(s)\n",
    "starting <function get_example_status at 0x000000F0A2D660D0> with args () {}\n",
    "finished <function get_example_status at 0x000000F0A2D660D0> in 1.5626 second(s)\n",
    "finished <function main at 0x000000F0A2D661F0> in 5.8909 second(s)\n",
    "```\n",
    "\n",
    "Note how the total runtime of the main coroutine is roughly the sum of time for all the tasks to get\n",
    "the status we ran, meaning that we did not have any concurrency advantage.\n",
    "\n",
    "This is again because the `requests` library is blocking, meaning it will block whichever thread it is run on. Since `asyncio` only has one thread, the `requests` library blocks the event loop from doing anything concurrently.\n",
    "\n",
    "As a rule, most APIs you employ now are blocking and won’t work out of the box\n",
    "with asyncio. You need to use a library that supports coroutines and utilizes non-\n",
    "blocking sockets. This means that if the library you are using does not return coroutines\n",
    "and you aren’t using await in your own coroutines, you’re likely making a blocking call.\n",
    "\n",
    "In the above example we can use a library such as `aiohttp`, which uses non-block-\n",
    "ing sockets and returns coroutines to get proper concurrency. We’ll introduce this\n",
    "library later. If you need to use the `requests` library, you can still use `async` syntax, but you’ll need to explicitly tell `asyncio` to use multithreading with a *thread pool executor*. We’ll see later how to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb04efd",
   "metadata": {},
   "source": [
    "#### Accessing and manually managing the event loop\n",
    "\n",
    "Until now, we have used the convenient `asyncio.run` to run our application and create the event loop for us behind the scenes. However, there may be cases in which we don’t want the functionality that `asyncio.run` provides. As an example, we may want to execute custom logic to stop tasks that differ from what `asyncio.run` does, such as letting any remaining tasks finish instead of stopping them.\n",
    "\n",
    "In addition, we may want to access methods available on the event loop itself. These methods are typically lower level and, as such, should be used sparingly. However, if you want to perform tasks, such as working directly with sockets or scheduling a task to run at a specific time in the future, you’ll need to access the event loop. While we won’t, and shouldn’t, be managing the event loop extensively, this will be necessary from time to time.\n",
    "\n",
    "We can create an event loop by using the `asyncio.new_event_loop` method. This will return an event loop instance. With this, we have access to all the low-level methods that the event loop has to offer. With the event loop we have access to a method named `run_until_complete`, which takes a coroutine and runs it until it finishes. Once we are done with our event loop, we need to close it to free any resources it was using. This should normally be in a `finally` block so that any exceptions thrown don’t stop us from closing the loop. Using these concepts, we can create a loop and run an `asyncio` application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e6b83341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async16.py\n"
     ]
    }
   ],
   "source": [
    "%%file async16.py\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    print(\"Running main\")\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "loop = asyncio.new_event_loop()\n",
    "\n",
    "try:\n",
    "    loop.run_until_complete(main())\n",
    "finally:\n",
    "    print(\"Done!\")\n",
    "    loop.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735dff44",
   "metadata": {},
   "source": [
    "The above code is similar to what happens when we call `asyncio.run` with the difference being that this does not perform canceling any remaining tasks. If we want any special cleanup logic, we would do so in our `finally` clause.\n",
    "\n",
    "From time to time, we may need to access the currently running event loop. `asyncio` exposes the `asyncio.get_running_loop` function that allows us to get the current event loop. As an example, let’s look at `call_soon`, which will schedule a function to run on the next iteration of the event loop.\n",
    "\n",
    "##### Accessing the event loop\n",
    "\n",
    "In the following example, our main coroutine gets the event loop with `asyncio.get_running_loop` and tells it to run `call_later`, which takes a function and will run it on the next iteration of the event loop. In addition, there is an `asyncio.get_event_loop` function that lets you access the event loop.\n",
    "\n",
    "This function can potentially create a new event loop if it is called when one is not already running, leading to strange behavior. It is recommended to use `get_running_loop`, as this will throw an exception if an event loop isn’t running, avoiding any surprises.\n",
    "\n",
    "While we shouldn’t use the event loop frequently in our applications, there are times when we will need to configure settings on the event loop or use low-level functions. We’ll see an example of configuring the event loop in the next section on debug mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df4832db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async17.py\n"
     ]
    }
   ],
   "source": [
    "%%file async17.py\n",
    "\n",
    "import asyncio\n",
    "\n",
    "async def delay(delay_seconds: int) -> int:\n",
    "    print(f'sleeping for {delay_seconds} second(s)')\n",
    "    await asyncio.sleep(delay_seconds)\n",
    "    print(f'finished sleeping for {delay_seconds} second(s)')\n",
    "\n",
    "def call_later():\n",
    "    print(\"I'm being called in the future!\")\n",
    "\n",
    "async def main():\n",
    "    loop = asyncio.get_running_loop()\n",
    "    loop.call_soon(call_later)\n",
    "    await delay(1)\n",
    "\n",
    "asyncio.run(main())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcea96b",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "sleeping for 1 second(s)\n",
    "I'm being called in the future!\n",
    "finished sleeping for 1 second(s)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e29e0",
   "metadata": {},
   "source": [
    "#### Using debug mode\n",
    "\n",
    "In previous sections, we mentioned how coroutines should always be awaited at some point in the application. We also saw the drawbacks of running CPU-bound and other blocking code inside coroutines and tasks. It can, however, be hard to tell if a coroutine is taking too much time on CPU, or if we accidently forgot an await somewhere in our application. Luckily, asyncio gives us a debug mode to help us diagnose these situations.\n",
    "\n",
    "There are a few different ways to run in debug mode.\n",
    "\n",
    " - Using `ayncio.run` - `asyncio.run(coroutine(), debug=True)`\n",
    " - Using command-line arguments - `python3 -X dev program.py` (Using -X flag)\n",
    " - Using environment variables - `PYTHONASYINCIODEBUG=1 python3 program.py`\n",
    " \n",
    " In debug mode, we’ll see informative messages logged when a coroutine takes too\n",
    "long. Let’s test this out by trying to run CPU-bound code in a task to see if we get a\n",
    "warning, as shown in the following listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ec487a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting async18.py\n"
     ]
    }
   ],
   "source": [
    "%%file async18.py\n",
    "\n",
    "import asyncio\n",
    "from async_timed import async_timed\n",
    "\n",
    "@async_timed()\n",
    "async def cpu_bound_work():\n",
    "    counter = 0\n",
    "    for i in range(100000000):\n",
    "        counter = counter + 1\n",
    "    return counter\n",
    "\n",
    "async def main():\n",
    "    task_one = asyncio.create_task(cpu_bound_work())\n",
    "    await task_one\n",
    "\n",
    "asyncio.run(main(), debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1c3a2",
   "metadata": {},
   "source": [
    "Output\n",
    "\n",
    "```\n",
    "starting <function cpu_bound_work at 0x000000C6DC7D29D0> with args () {}\n",
    "finished <function cpu_bound_work at 0x000000C6DC7D29D0> in 30.9647 second(s)\n",
    "Executing <Task finished name='Task-2' coro=<cpu_bound_work() done, defined at C:\\Users\\pc\n",
    "xyz\\miniconda3\\Notebooks\\My notebooks\\Python\\Python Basics\\async_timed.py:7> result=100000\n",
    "000 created at C:\\Users\\pcxyz\\miniconda3\\lib\\asyncio\\tasks.py:361> took 30.953 seconds\n",
    "```\n",
    "\n",
    "The default settings will log a warning if a coroutine takes longer than 100 milliseconds, but this may be longer or shorter than we’d like. To change this value, we can set the slow callback duration by accessing the event loop as we do in following code and setting `slow_callback_duration`. This is a floating-point value representing the seconds we want the slow callback duration to be.\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.slow_callback_duration = .250\n",
    "\n",
    "asyncio.run(main(), debug=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c461c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### Note\n",
    "\n",
    "Following material is taken from the blog [Python Concurrency: The Tricky Bits](https://python.hamel.dev/concurrency/) which in turn is based on David Beazley seminal talk on the topic. \n",
    "\n",
    "---\n",
    "\n",
    "**CPU-bound Task: Fibonacci Number**\n",
    "Let's first develop a CPU intensive task:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b20b8cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing fib.py\n"
     ]
    }
   ],
   "source": [
    "%%file fib.py\n",
    "\n",
    "#fibonacci number\n",
    "\n",
    "def fib(n):\n",
    "    if n <= 2: return 1\n",
    "    else: return fib(n-1) + fib(n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e735ec7",
   "metadata": {},
   "source": [
    "**A Simple Web Server**\n",
    "\n",
    "First, let's set up a web server using socket programming. It is advisable to go through [Python docs for `socket` module](https://docs.python.org/3/library/socket.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f32698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server-1.py\n"
     ]
    }
   ],
   "source": [
    "%%file server-1.py\n",
    "\n",
    "\n",
    "from socket import *\n",
    "from fib import fib \n",
    "\n",
    "def fib_server(address):\n",
    "    sock = socket(AF_INET, SOCK_STREAM) #(1st param: address family, 2nd param: socket type)\n",
    "    sock.setsockopt(SOL_SOCKET, SO_REUSEADDR,1) #(lev,opt,value)see comment 'a' in end of code for understanding params\n",
    "    sock.bind(address)\n",
    "    sock.listen(5)  #'5' number of unaccepted connections the system will allow before refusing new connections.\n",
    "    while True:\n",
    "        client,addr = sock.accept() #accept a connection. Returns (conn,addr), conn is new socket obj for data exchange\n",
    "        print(\"Connection\", addr)\n",
    "        fib_handler(client) # passes the client to a handler which will listen for input data.\n",
    "        \n",
    "def fib_handler(client):\n",
    "    while True:\n",
    "        req = client.recv(128)  # waits for data that sent by the client.\n",
    "        if not req: break\n",
    "        result = fib(int(req))\n",
    "        resp = str(result).encode('ascii') + b'\\n'\n",
    "        client.send(resp) # sends data back to the client.\n",
    "        print(resp)\n",
    "    print(\"Closed\")\n",
    "    \n",
    "fib_server(('', 25000))\n",
    "\n",
    "#'a' -  refer this https://pubs.opengroup.org/onlinepubs/7908799/xns/getsockopt.html \n",
    "# setsockopt params means search SO_REUSEADDR on the socket level (SOL_SOCKET)itself and set it to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43c2c1",
   "metadata": {},
   "source": [
    "To run this server, open a command prompt window and run `python server-1.py`. Your terminal will appear to hang. That’s because the server is blocked, or suspended, on `.accept()`. Now open another command prompt window and first test if command `telnet` is available. If not, go to Control Panel ->Turn Windows features on or off -> select 'telnet client' and 'telnet server' options and then click 'OK'. In other command prompt window, run `telnet localhost 25000`. After running this, you'll see a message `Connection ('127.0.0.1', 57148)` in first command prompt window. Now second window is ready to take input. You can enter any number and it will output Fibonacci number. (Unlike in Bash, the formatting is quite weird in Windows).\n",
    "\n",
    "If you open yet another command prompt window and establish an another client there, you'd see it just doesn't take any input. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "33f936e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFKAQAAAABTUiuoAAAB6klEQVR4nO2bQWrkMBBFX40MWco3yFHkm82Z5gb2UXKAAXvZoPBnYcl2ZxjwJDitkKpNG/EWH4pfqiq3TZyM6cdZEhx11FFHHXX0StRKdMBiZgNgw1KPh8sFOPo/aJIkzcD0LAGvppEgSdI9eo0AR89EV36XHtIvsPTSZbH067FByJcKcPQd2doj3oxDjq4W4OhH0KkHaQYbHiPA0X9H9VYUsAAsT7JiMDjOzg/X6mhBJzMz64E0A+nlaW01zMzsMwQ4eiZWbx0tFG8myOj+uAGtjrL26GkGIEiag+rTdiZJ48O1Ooq2IEmCKJHmIJIy+9Dl2WoALdka453BxpiBmCEpl9nZs/V4dKuEQSUphDVvGqMkKePeagXdvJXRCKyOAtjz5t5qBaVuAvedYH1Kq63cW+2gtRJu5RBgr4T18vJsNYUuHUzPN9s7QVjMDhlsR+v3RQ9bXU1DB1P/GwPqBqNu4xvQ6uhh3jp2h7VFrJeXV8Im0K3LAMqopbLQWIug31vtodu7Y/s5gw37dDx/jgBHT8VhT7h1FGXyWsM3Ty2jMWNDzJRyqJv/i6YZ9O83/QQBr0DMCILsSgGOvgONkkZA49JhA0Fm/f3r/ma0fl/0bU9Y+r+orTvEe8JmUPOvFhx11FFHHf1C6B/X1HcfiNHGUAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<qrcode.image.pil.PilImage at 0xb9015c8130>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qrcode\n",
    "\n",
    "qr = qrcode.QRCode()\n",
    "qr.add_data('twitter.com/prakharseth19')\n",
    "qr.make()\n",
    "qr.make_image(fill_color = 'black', back_color = \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8f97a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
