{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46e7be87",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### `concurrent.futures`\n",
    "\n",
    "The `concurrent.futures` modules provides interfaces for running tasks using pools of thread or process workers. The APIs are the same, so applications can switch between threads and processes with minimal changes.\n",
    "\n",
    "The module provides two types of classes for interacting with the pools. *Executors* are used for managing pools of workers, and *futures* are used for managing results computed by the workers. To use a pool of workers, an application creates an instance of the appropriate executor class and then submits tasks for it to run. When each task is started, a `Future` instance is returned. When the result of the task is needed, an application can use the `Future` to block until the result is available. Various APIs are provided to make it convenient to wait for tasks to complete, so that the `Future` objects do not need to be managed directly.\n",
    "\n",
    "[Python Doc](https://docs.python.org/3/library/concurrent.futures.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002583f",
   "metadata": {},
   "source": [
    "#### API Structure\n",
    "\n",
    "\n",
    "This module provides two classes: `Executor` class and `Future` class. `Executor` class is further subclassed into `ThreadPoolExecutor` class and `ProcessPoolExecutor`.\n",
    "\n",
    "                                     concurrent.futures\n",
    "                                            |\n",
    "                                            |\n",
    "                       -------------------------------------------------------------------------------\n",
    "                       |                                                 |                            |\n",
    "                       |                                                 |                            |\n",
    "                    Executor class                                     Future class                module functions\n",
    "                       |                                                 |                            |\n",
    "                       |--subclasses--ThreadPoolExecutor                 |                             --wait()\n",
    "                       |            |                                    |                             --as_completed()\n",
    "                       |            --ProcessPoolExecutor                |\n",
    "                       |                                                 |\n",
    "                       |--Methods--submit()-> returns Future instances-->|--methods\n",
    "                                 --map()                                       |\n",
    "                                 --shutdown()                                 ---cancel()\n",
    "                                                                              ---cancelled()\n",
    "                                                                              ---running()    \n",
    "                                                                              ---done()\n",
    "                                                                              ---result()\n",
    "                                                                              ---exception()\n",
    "                                                                              ---add_done_callback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97b990e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures as conf\n",
    "\n",
    "with conf.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "    future = executor.map(pow, [2,3], [2,2])\n",
    "    for i in future:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cea21",
   "metadata": {},
   "source": [
    "The `ThreadPoolExecutor` manages a set of worker threads, passing tasks to them as they become available for more work. This example uses `map()` to concurrently produce a set of results from an input iterable. The task uses `time.sleep()` to pause a different amount of time to demonstrate that, regardless of the order of execution of concurrent tasks, `map()` always returns the values in order based on the inputs.\n",
    "\n",
    "**`map(func, *iterables, timeout=None, chunksize=1)`**\n",
    "\n",
    "It returns a type of iterator. Similar to `map(func, *iterables)` except:\n",
    " - the iterables are collected immediately rather than lazily;\n",
    " - `func` is executed asynchronously and several calls to func may be made concurrently.\n",
    "\n",
    "**`class concurrent.futures.ThreadPoolExecutor(max_workers=None, thread_name_prefix='', initializer=None, initargs=())`**\n",
    "\n",
    "`initializer` is an optional callable that is called at the start of each worker thread; `initargs` is a tuple of arguments passed to the `initializer`. Should `initializer` raise an exception, all currently pending jobs will raise a `BrokenThreadPool`, as well as any attempt to submit more jobs to the pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981faa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conf1.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf1.py\n",
    "\n",
    "from concurrent import futures\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping {}'.format(threading.current_thread().name,n))\n",
    "    time.sleep(n / 10)\n",
    "    print('{}: done with {}'.format(threading.current_thread().name,n))\n",
    "    return n / 10\n",
    "\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "print('main: starting')\n",
    "results = ex.map(task, range(5, 0, -1))\n",
    "print('main: unprocessed results {}'.format(results))\n",
    "print('main: waiting for real results')\n",
    "real_results = list(results)\n",
    "print('main: results: {}'.format(real_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c56fb",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "main: starting\n",
    "ThreadPoolExecutor-0_0: sleeping 5\n",
    "ThreadPoolExecutor-0_1: sleeping 4\n",
    "main: unprocessed results <generator object Executor.map.<locals>.result_iterator at 0x0000007700DD7890>\n",
    "main: waiting for real results\n",
    "ThreadPoolExecutor-0_1: done with 4\n",
    "ThreadPoolExecutor-0_1: sleeping 3\n",
    "ThreadPoolExecutor-0_0: done with 5\n",
    "ThreadPoolExecutor-0_0: sleeping 2\n",
    "ThreadPoolExecutor-0_0: done with 2\n",
    "ThreadPoolExecutor-0_0: sleeping 1\n",
    "ThreadPoolExecutor-0_1: done with 3\n",
    "ThreadPoolExecutor-0_0: done with 1\n",
    "main: results: [0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5123f658",
   "metadata": {},
   "source": [
    "The return value from `map()` is actually a special type of iterator that knows to wait for each response as the main program iterates over it.\n",
    "\n",
    "In addition to using `map()`, it is possible to schedule an individual task with an executor using `submit()`, and use the `Future` instance returned to wait for that task’s results.\n",
    "\n",
    " **`submit(fn, /, *args, **kwargs)`**\n",
    "\n",
    "It returns an instance of `Future` class. It schedules the callable, `fn`, to be executed as `fn(*args, **kwargs)` and returns a `Future` object representing the execution of the callable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1629e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf2.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf2.py\n",
    "\n",
    "from concurrent import futures\n",
    "import threading\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping {}'.format(threading.current_thread().name,n))\n",
    "    time.sleep(n / 10)\n",
    "    print('{}: done with {}'.format(threading.current_thread().name,n))\n",
    "    return n / 10\n",
    "\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "print('main: starting')\n",
    "f = ex.submit(task, 5)\n",
    "print('main: future: {}'.format(f))\n",
    "print('main: waiting for results')\n",
    "result = f.result()\n",
    "print('main: result: {}'.format(result))\n",
    "print('main: future after result: {}'.format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181490d",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "main: starting\n",
    "ThreadPoolExecutor-0_0: sleeping 5\n",
    "main: future: <Future at 0xba34fbe640 state=running>\n",
    "main: waiting for results\n",
    "ThreadPoolExecutor-0_0: done with 5\n",
    "main: result: 0.5\n",
    "main: future after result: <Future at 0xba34fbe640 state=finished returned float>\n",
    "```\n",
    "\n",
    "The status of the future changes after the tasks is completed and the result is made available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1017641a",
   "metadata": {},
   "source": [
    "#### Waiting for Tasks in Any Order\n",
    "\n",
    "Invoking the `result()` method of a `Future` blocks until the task completes (either by returning a value or raising an exception), or is canceled. The results of multiple tasks can be accessed in the order the tasks were scheduled using `map()`. If it does not matter what order the results should be processed, use `as_completed()` to process them as each task finishes.\n",
    "\n",
    "**`concurrent.futures.as_completed(fs, timeout=None)`**\n",
    "\n",
    "Note that, unlike class methods `submit() or map()`, `as_completed` is a module function.\n",
    "\n",
    "Returns an iterator over the `Future` instances (possibly created by different `Executor` instances) given by `fs` that yields futures as they complete (finished or cancelled futures). Any futures given by `fs` that are duplicated will be returned once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5d27efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conf3.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf3.py\n",
    "\n",
    "from concurrent import futures\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    time.sleep(random.random())\n",
    "    return (n, n / 10)\n",
    "\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=5)\n",
    "print('main: starting')\n",
    "\n",
    "wait_for = [\n",
    "    ex.submit(task, i) for i in range(5, 0, -1)]\n",
    "\n",
    "for f in futures.as_completed(wait_for):\n",
    "    print('main: result: {}'.format(f.result()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962b03c5",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "main: starting\n",
    "main: result: (2, 0.2)\n",
    "main: result: (3, 0.3)\n",
    "main: result: (4, 0.4)\n",
    "main: result: (1, 0.1)\n",
    "main: result: (5, 0.5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1415468c",
   "metadata": {},
   "source": [
    "There is another module function `wait`.\n",
    "\n",
    "**`concurrent.futures.wait(fs, timeout=None, return_when=ALL_COMPLETED)`**\n",
    "\n",
    "Wait for the `Future` instances (possibly created by different `Executor` instances) given by `fs` to complete. Duplicate futures given to `fs` are removed and will be returned only once. Returns a named 2-tuple of sets. The first set, named `done`, contains the futures that completed (finished or cancelled futures) before the wait completed. The second set, named `not_done`, contains the futures that did not complete (pending or running futures).\n",
    "\n",
    "As of writing this, I couldn't immediately find an example of this function so I modified the above program:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a3f7435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf4.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf4.py\n",
    "\n",
    "from concurrent import futures\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    time.sleep(random.random())\n",
    "    return (n, n / 10)\n",
    "\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=5)\n",
    "print('main: starting')\n",
    "\n",
    "wait_for = [\n",
    "    ex.submit(task, i) for i in range(5, 0, -1)]\n",
    "\n",
    "print(futures.wait(wait_for))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b2fa77",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "main: starting\n",
    "DoneAndNotDoneFutures(done={<Future at 0x702e8bca90 state=finished returned tupl\n",
    "e>, <Future at 0x702e8bc700 state=finished returned tuple>, <Future at 0x702e89e\n",
    "f40 state=finished returned tuple>, <Future at 0x702e8bc370 state=finished retur\n",
    "ned tuple>, <Future at 0x702e8b1fa0 state=finished returned tuple>}, not_done=set())\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a304c1",
   "metadata": {},
   "source": [
    "**Future Objects**\n",
    "\n",
    "As mentioned elsewhere, `Executor.submit()` method returns instances of `Future` class. These instances have following methods available - \n",
    "\n",
    " - `cancel()` - Attempt to cancel the call. If the call is currently being executed or finished running and cannot be cancelled then the method will return `False`, otherwise the call will be cancelled and the method will return `True`.\n",
    " \n",
    " \n",
    " - `cancelled()` - Return `True` if the call was successfully cancelled.\n",
    " \n",
    " \n",
    " - `running()` - Return `True` if the call is currently being executed and cannot be cancelled.\n",
    " \n",
    " \n",
    " - `done()` - Return `True` if the call was successfully cancelled or finished running.\n",
    " \n",
    " \n",
    " - `result(timeout = None)` - Return the value returned by the call. If the call hasn’t yet completed then this method will wait up to `timeout` seconds. If the call hasn’t completed in `timeout` seconds, then a `TimeoutError` will be raised. `timeout` can be an `int` or `float`. If `timeout` is not specified or `None`, there is no limit to the wait time. If the future is cancelled before completing then `CancelledError` will be raised. If the call raised an exception, this method will raise the same exception.\n",
    "\n",
    "\n",
    " - `exception(timeout = None)` - Return the exception raised by the call. If the call hasn’t yet completed then this method will wait up to `timeout` seconds. If the call hasn’t completed in `timeout` seconds, then a `TimeoutError` will be raised. `timeout` can be an `int` or `float`. If `timeout` is not specified or `None`, there is no limit to the wait time.\n",
    "\n",
    "    If the future is cancelled before completing then `CancelledError` will be raised.\n",
    "\n",
    "    If the call completed without raising, `None` is returned.\n",
    "\n",
    "\n",
    " - `add_done_callback(fn)` - Attaches the callable `fn` to the future. `fn` will be called, with the future as its only argument, when the future is cancelled or finishes running.\n",
    "\n",
    "    Added callables are called in the order that they were added and are always called in a thread belonging to the process that added them. If the callable raises an `Exception` subclass, it will be logged and ignored. If the callable raises a `BaseException` subclass, the behavior is undefined.\n",
    "\n",
    "    If the future has already completed or been cancelled, `fn` will be called immediately.\n",
    "\n",
    "\n",
    "**Future Callbacks**\n",
    "\n",
    "To take some action when a task completed, without explicitly waiting for the result, use `add_done_callback()` to specify a new function to call when the `Future` is done. The callback should be a callable taking a single argument, the `Future`\n",
    "instance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abbabd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf5.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf5.py\n",
    "\n",
    "from concurrent import futures\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping'.format(n))\n",
    "    time.sleep(0.5)\n",
    "    print('{}: done'.format(n))\n",
    "    return n / 10\n",
    "\n",
    "\n",
    "def done(fn):\n",
    "    if fn.cancelled():\n",
    "        print('{}: canceled'.format(fn.arg))\n",
    "    elif fn.done():\n",
    "        error = fn.exception()\n",
    "        if error:\n",
    "            print('{}: error returned: {}'.format(fn.arg, error))\n",
    "        else:\n",
    "            result = fn.result()\n",
    "            print('{}: value returned: {}'.format(fn.arg, result))\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "    print('main: starting')\n",
    "    f = ex.submit(task, 5)\n",
    "    f.arg = 5\n",
    "    f.add_done_callback(done)\n",
    "    result = f.result()            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619572fb",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "main: starting\n",
    "5: sleeping\n",
    "5: done\n",
    "5: value returned: 0.5\n",
    "```\n",
    "\n",
    "The callback is invoked regardless of the reason the Future is considered “done,” so it is necessary to check the status of the object passed in to the callback before using it in any way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e8ac9",
   "metadata": {},
   "source": [
    "**Canceling Tasks**\n",
    "\n",
    "A `Future` can be canceled, if it has been submitted but not started, by calling its `cancel()` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91cf802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf6.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf6.py\n",
    "\n",
    "from concurrent import futures\n",
    "import time\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: sleeping'.format(n))\n",
    "    time.sleep(0.5)\n",
    "    print('{}: done'.format(n))\n",
    "    return n / 10\n",
    "\n",
    "\n",
    "def done(fn):\n",
    "    if fn.cancelled():\n",
    "        print('{}: canceled'.format(fn.arg))\n",
    "    elif fn.done():\n",
    "        print('{}: not canceled'.format(fn.arg))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "    print('main: starting')\n",
    "    tasks = []\n",
    "\n",
    "    for i in range(10, 0, -1):\n",
    "        print('main: submitting {}'.format(i))\n",
    "        f = ex.submit(task, i)\n",
    "        f.arg = i\n",
    "        f.add_done_callback(done)\n",
    "        tasks.append((i, f))\n",
    "\n",
    "    for i, t in reversed(tasks):\n",
    "        if not t.cancel():\n",
    "            print('main: did not cancel {}'.format(i))\n",
    "\n",
    "    ex.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8432b7a7",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "main: starting\n",
    "main: submitting 10\n",
    "10: sleeping\n",
    "main: submitting 9\n",
    "9: sleeping\n",
    "main: submitting 8\n",
    "main: submitting 7\n",
    "main: submitting 6\n",
    "main: submitting 5\n",
    "main: submitting 4\n",
    "main: submitting 3\n",
    "main: submitting 2\n",
    "main: submitting 1\n",
    "1: canceled\n",
    "2: canceled\n",
    "3: canceled\n",
    "4: canceled\n",
    "5: canceled\n",
    "6: canceled\n",
    "7: canceled\n",
    "8: canceled\n",
    "main: did not cancel 9\n",
    "main: did not cancel 10\n",
    "10: done\n",
    "10: not canceled\n",
    "9: done\n",
    "9: not canceled\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4403d9",
   "metadata": {},
   "source": [
    "**Exceptions in Tasks**\n",
    "\n",
    "If a task raises an unhandled exception, it is saved to the `Future` for the task and made available through the `result()` or `exception()` methods.\n",
    "\n",
    "If `result()` is called after an unhandled exception is raised within a task function, the same exception is re-raised in the current context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd88a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf7.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf7.py\n",
    "\n",
    "from concurrent import futures\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print('{}: starting'.format(n))\n",
    "    raise ValueError('the value {} is no good'.format(n))\n",
    "\n",
    "\n",
    "ex = futures.ThreadPoolExecutor(max_workers=2)\n",
    "print('main: starting')\n",
    "f = ex.submit(task, 5)\n",
    "\n",
    "error = f.exception()\n",
    "print('main: error: {}'.format(error))\n",
    "\n",
    "try:\n",
    "    result = f.result()\n",
    "except ValueError as e:\n",
    "    print('main: saw error \"{}\" when accessing result'.format(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db815564",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "main: starting\n",
    "5: starting\n",
    "main: error: the value 5 is no good\n",
    "main: saw error \"the value 5 is no good\" when accessing result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26459066",
   "metadata": {},
   "source": [
    "#### Context Manager\n",
    "\n",
    "Executors work as context managers, running tasks concurrently and waiting for them all to complete. When the context manager exits, the `shutdown()` method of the executor is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7d1835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf8.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf8.py\n",
    "\n",
    "from concurrent import futures\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    print(n)\n",
    "\n",
    "\n",
    "with futures.ThreadPoolExecutor(max_workers=2) as ex:\n",
    "    print('main: starting')\n",
    "    ex.submit(task, 1)\n",
    "    ex.submit(task, 2)\n",
    "    ex.submit(task, 3)\n",
    "    ex.submit(task, 4)\n",
    "\n",
    "print('main: done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb4561",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "main: starting\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "main: done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6e0b2",
   "metadata": {},
   "source": [
    "**Deadlocks**\n",
    "\n",
    "Deadlocks can occur when the callable associated with a `Future` waits on the results of another `Future`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9059ec9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deadlock1.py\n"
     ]
    }
   ],
   "source": [
    "%%file deadlock1.py\n",
    "\n",
    "import concurrent.futures as conf\n",
    "import time\n",
    "\n",
    "def wait_on_b():\n",
    "    time.sleep(5)\n",
    "    print(b.result())  # b will never complete because it is waiting on a.\n",
    "    return 5\n",
    "\n",
    "def wait_on_a():\n",
    "    time.sleep(5)\n",
    "    print(a.result())  # a will never complete because it is waiting on b.\n",
    "    return 6\n",
    "\n",
    "\n",
    "executor = conf.ThreadPoolExecutor(max_workers=2)\n",
    "a = executor.submit(wait_on_b)\n",
    "b = executor.submit(wait_on_a)\n",
    "print(a.running())\n",
    "print(b.running())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c53804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deadlock2.py\n"
     ]
    }
   ],
   "source": [
    "%%file deadlock2.py\n",
    "\n",
    "import concurrent.futures as conf\n",
    "\n",
    "def wait_on_future():\n",
    "    f = executor.submit(pow, 5, 2)\n",
    "    # This will never complete because there is only one worker thread and\n",
    "    # it is executing this function.\n",
    "    print(f.result())\n",
    "\n",
    "executor = conf.ThreadPoolExecutor(max_workers=1)\n",
    "executor.submit(wait_on_future)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4423138",
   "metadata": {},
   "source": [
    "**Process Pools**\n",
    "\n",
    "The `ProcessPoolExecutor` works in the same way as `ThreadPoolExecutor`, but uses processes instead of threads. This allows CPU-intensive operations to use a separate CPU and not be blocked by the CPython interpreter’s global interpreter lock.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0adf3a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conf9.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf9.py\n",
    "\n",
    "from concurrent import futures\n",
    "import os\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    return (n, os.getpid())\n",
    "\n",
    "def main():\n",
    "    ex = futures.ProcessPoolExecutor(max_workers=2)\n",
    "    results = ex.map(task, range(5, 0, -1))\n",
    "\n",
    "    for n, pid in results:\n",
    "        print('ran task {} in process {}'.format(n, pid))\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92780b74",
   "metadata": {},
   "source": [
    "above example is raising `BrokenProcessPool` exception. Not sure what went wrong. \n",
    "\n",
    "Edit: This [SO Post](https://stackoverflow.com/questions/15900366/all-example-concurrent-futures-code-is-failing-with-brokenprocesspool?rq=1) raised somewhat similar issue. As indicated by this post, I used the `if __name__== '__main__'` idiom and reran the code. It worked.\n",
    "\n",
    "I later got to know that [Python official docs](https://docs.python.org/3.7/library/multiprocessing.html#the-process-class) explicitly asks us to use `if __name__== '__main__'` idiom to protect the entry point in `multiprocessing` codes.\n",
    "\n",
    "Output:\n",
    "\n",
    "```\n",
    "ran task 5 in process 4152\n",
    "ran task 4 in process 1592\n",
    "ran task 3 in process 4152\n",
    "ran task 2 in process 1592\n",
    "ran task 1 in process 4152\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb536a7",
   "metadata": {},
   "source": [
    "As with the thread pool, individual worker processes are reused for multiple tasks.\n",
    "\n",
    "If something happens to one of the worker processes to cause it to exit unexpectedly, the `ProcessPoolExecutor` is considered “broken” and will no longer schedule tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d589fc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf10.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf10.py\n",
    "\n",
    "from concurrent import futures\n",
    "import os\n",
    "import signal\n",
    "\n",
    "\n",
    "with futures.ProcessPoolExecutor(max_workers=2) as ex:\n",
    "    print('getting the pid for one worker')\n",
    "    f1 = ex.submit(os.getpid)\n",
    "    pid1 = f1.result()\n",
    "\n",
    "    print('killing process {}'.format(pid1))\n",
    "    os.kill(pid1, signal.SIGHUP)\n",
    "\n",
    "    print('submitting another task')\n",
    "    f2 = ex.submit(os.getpid)\n",
    "    try:\n",
    "        pid2 = f2.result()\n",
    "    except futures.process.BrokenProcessPool as e:\n",
    "        print('could not start new tasks: {}'.format(e))\n",
    "        \n",
    "#although it was supposed to raise exception, which it did, I'm still not sure if this ran as intended.        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d1edc",
   "metadata": {},
   "source": [
    "The `BrokenProcessPool` exception is actually thrown when the results are processed, rather than when the new task is submitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7c130f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf11.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf11.py\n",
    "\n",
    "#ProcessPoolExecutor example\n",
    "#this example is from Python docs\n",
    "\n",
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "PRIMES = [\n",
    "    112272535095293,\n",
    "    112582705942171,\n",
    "    112272535095293,\n",
    "    115280095190773,\n",
    "    115797848077099,\n",
    "    1099726899285419]\n",
    "\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    if n == 2:\n",
    "        return True\n",
    "    if n % 2 == 0:\n",
    "        return False\n",
    "\n",
    "    sqrt_n = int(math.floor(math.sqrt(n)))\n",
    "    for i in range(3, sqrt_n + 1, 2):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def main():\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):\n",
    "            print('%d is prime: %s' % (number, prime))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277476d7",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "112272535095293 is prime: True\n",
    "112582705942171 is prime: True\n",
    "112272535095293 is prime: True\n",
    "115280095190773 is prime: True\n",
    "115797848077099 is prime: True\n",
    "1099726899285419 is prime: False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37b11ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing conf12.py\n"
     ]
    }
   ],
   "source": [
    "%%file conf12.py\n",
    "\n",
    "#ThreadPoolExecutor example\n",
    "#this example is from Python docs\n",
    "\n",
    "\n",
    "import concurrent.futures\n",
    "import urllib.request\n",
    "\n",
    "URLS = ['http://www.foxnews.com/',\n",
    "        'http://www.cnn.com/',\n",
    "        'http://europe.wsj.com/',\n",
    "        'http://www.bbc.co.uk/',\n",
    "        'http://some-made-up-domain.com/']\n",
    "\n",
    "# Retrieve a single page and report the URL and contents\n",
    "def load_url(url, timeout):\n",
    "    with urllib.request.urlopen(url, timeout=timeout) as conn:\n",
    "        return conn.read()\n",
    "\n",
    "# We can use a with statement to ensure threads are cleaned up promptly\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    # Start the load operations and mark each future with its URL\n",
    "    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}\n",
    "    for future in concurrent.futures.as_completed(future_to_url):\n",
    "        url = future_to_url[future]\n",
    "        try:\n",
    "            data = future.result()\n",
    "        except Exception as exc:\n",
    "            print('%r generated an exception: %s' % (url, exc))\n",
    "        else:\n",
    "            print('%r page is %d bytes' % (url, len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413578f0",
   "metadata": {},
   "source": [
    "Output:\n",
    "\n",
    "```\n",
    "'http://europe.wsj.com/' generated an exception: HTTP Error 403: Forbidden\n",
    "'http://www.bbc.co.uk/' page is 457219 bytes\n",
    "'http://www.foxnews.com/' page is 282703 bytes\n",
    "'http://www.cnn.com/' page is 1145339 bytes\n",
    "'http://some-made-up-domain.com/' generated an exception: HTTP Error 403: Forbidden\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441acbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
