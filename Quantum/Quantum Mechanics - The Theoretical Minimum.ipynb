{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbda9165",
   "metadata": {},
   "source": [
    "### Lecture 1 : Systems and Experiences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39200586",
   "metadata": {},
   "source": [
    "#### 1.1 Quantum Mechanics Is Different\n",
    "\n",
    "The classical and quantum worlds have some important things in common. Quantum Mechanics, however, is different in two ways:\n",
    "\n",
    " - *Different Abstractions.* Quantum abstractions are fundamentally different from classical ones. For example, we'll see that the ideaj of a state in quantum mechanics is conceptually very different from its classical counterpart. States are represented by different mathematical objectsand have diffferent logical structure. \n",
    " \n",
    "\n",
    "- *States and Measurements.* In the classical world, the relationship between the state of a system and the result of a measurement on that system is very straightforward. In fact, it is trivial. The labels that describe a state (the position and momentum of a particle, for example) are the *same* labels that characterize measurements of that state. To put in another way,  one  can perform an experiment to determine the state of a system. In the quantum world, thhis is not true. States and measurements are two defferent things, and the relationship betweeen them is subtle and nonintuitive. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86560943",
   "metadata": {},
   "source": [
    "#### 1.2 Spins and Qubits\n",
    "\n",
    "--skipped--\n",
    "\n",
    "The isolated quantum spin is an example of the general class of simple systems we call qubits-quantum bits- that play the same role in quantum world as logical bits play in defining the state of your computer. Many systems-maybe even all systems-can be built up by combining qubits. Thus in learning about them, we are learning about a great deal more. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5964be",
   "metadata": {},
   "source": [
    "#### 1.3 An Experiment\n",
    "\n",
    "Let's say we have a coin that can show either heads *(H)* or tails *(T)*. We can call this a two-state system, or a bit,with the two states being *H* and *T*. More formally we invent a \"degree of freedom\" called $\\sigma$ that can take on two values, namely $+ {1}$ and $-{1}$. The state $H$ is replaced by\n",
    "\n",
    "$$\\sigma= +1  $$\n",
    "\n",
    "and the state $T$ by \n",
    "\n",
    "$$\\sigma= -1  $$.\n",
    "\n",
    "Classically, that's all there is to the space of states. The system is either in state $\\sigma= +1$ or $\\sigma=- 1$ and there is nothing in between. In quantum mechanics, we'll think of this system as a qubit. In quantum mechanics, we'll think of this system as a qubit. \n",
    "\n",
    "*Volume I* also discussed simple evolution laws that tell us how to update the state from instant to instant. The simplest law is just that nothing happens. In that case, if we from one discrete instant *(n)* to the next *(n + 1)*, the law of evolution is \n",
    "\n",
    "$$\\sigma(n+1)=\\sigma(n) \\     \\   \\     \\      \\     \\   \\    \\text{eq}(1.1)$$ \n",
    "\n",
    "Let's expose a hidden assumption that we are careless about in classical phyics. An experiment involves more than just a system to study. It also involves an apparatus $\\mathbf{A}$ to make measurements and record the results of the measurements. In the case of two-state system, the apparatus interacts with the system (the spin) and recrods the value of $\\sigma$. There is also a \"this end up\" arrow on the apparatus as it shows how the apparatus is oriented in space, and its direction will affect the outcomes of our measurements. We begin by pointing it along the $z$ axis. Initially, we have no knowledgde of whether $\\sigma= +1 $ or $\\sigma= -1  $.\n",
    "\n",
    "Suppose initially apparatus shows the reading $\\sigma= +1  $. Now we reset the the appratus to neutral and, without disturbing the spin, measure $\\sigma$ again. Assuming the simple law of Eq.1.1, we should get the same answer as we did the first time. \n",
    "\n",
    "We can also say this in the following way: The first interaction with the apparatus *prepares* the system in one of the two states. Subsequent experiments *confirm* that state. So far, there is no difference between and quantum physics.\n",
    "\n",
    "\n",
    "Also note that if we turn apparatus upside down and take the measurement, the measurement would be $\\sigma=-1$. From these results, we can conclude that $\\sigma$ is a degree of freedom that is associated with a sense of direction in space. In a sense, spin is a vector. \n",
    "\n",
    "If we are convinced that the spin is a vector, we would naturally describe it by three components $\\sigma_z$, $\\sigma_x$ and $\\sigma_y$. When the apparatus is upright along the $z$ axis, it is positioned to measure $\\sigma_z$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a29bb9",
   "metadata": {},
   "source": [
    "So far, there is still no difference between classical physics and quantum physics. The difference only becomes apparent when we rotate the apratus through an arbitrary angle, say 90 degrees. Now we rotate the apparatus so that the up-arrow points along the $x$ axis, and then make a measurement of what is presumably the $x$ component of the spin $\\sigma_x$.\n",
    "\n",
    "If in fact $\\sigma$ really represents the component of a vector along the up-arrow, one would expect to get zero. Why? Initially, we confirmed that $\\sigma$ was directed along the $z$ axis, suggesting that its component along $x$ must be zero. But we get a surprise when we measure $\\sigma_x$: Instead of giving $\\sigma_x$ as $0$, the apparatus gives either $\\sigma_x=+1$ or $\\sigma_x=-1$. We don't get any other result than $\\sigma \\pm{1}$. If the spin really is a vector, it is a very peculiar one indeed. \n",
    "\n",
    "The repeated experiment spits out a random series of plus-ones and minus-ones. Determinism has broken down, but in a particular way. If we do many repetitions, we will find that the numbers of $\\sigma_x=+1$ events and $\\sigma_x=-1$ events are statistically equal, meaning average value of $\\sigma$ is $0$. Instead of the classical result - namely, that the component of $\\sigma$ along the $x$ axis is zero - we find that the *averagde of these repeated measurements is zero*.  \n",
    " \n",
    "The situation is of course more general. We did not have to start with apparatus oriented along $z$. Pick any direction $\\hat{m}$ and start with the up-arrow pointing along $\\hat{m}$. Prepare a spin so that apparatus read $+1$. Then, without disturbing the spin, rotate the apparatus to the direction $\\hat{n}$. Assume the angle between the two directions is $\\theta$. A new experiment on the same spin will give random results $\\pm1$, but with an average value equal to the $cos\\theta$. (Note that both $\\hat{n}$ and $\\hat{m}$ are unit vectors). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e13a42c",
   "metadata": {},
   "source": [
    "The quantum mechanical notation for the statistical average of a quantity $Q$ is Dirac's bracket notation $\\langle{Q}\\rangle$. So we have\n",
    "\n",
    "$$\\langle{\\sigma}\\rangle=\\hat{n}.\\hat{m}$$\n",
    "\n",
    "**What we are learning is that quantum mechanical systems are not deterministic-the results of experiments can be statistically random-but if we repeat an experiment many times, average quantities can follow the expectations of classical physics, at least up to a point.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67eed7",
   "metadata": {},
   "source": [
    "#### 1.4 Experiments Are Never Gentle\n",
    "\n",
    "The gist is that all experiment are invasive and they disturb the system being studied. However, in classical physics, these disturbances are very small and doesn't really affect the measurement. \n",
    "\n",
    "In quantum mechanics, any interaction that is strong enough to measure some aspect of a system is necessarily strong enough to disrupt some other aspects of the same system. Thus, you can learn nothing about a quantum system without changing something else. \n",
    "\n",
    "In the experiment mentioned earlier, if we measure $\\sigma_z$ after measureing $\\sigma_x$, there is no guarantee we would again get $\\sigma_z$ as $1$. The intermediate measurement along $x$ axis will leave the spin in a completely random configuration as far as the next measurement is concerned. In fact, one simply cannot simultaneously know the components of the spin along two different axes, not in a reproducible way in any case. There is something fundamentally different about the state of a quantum system and the state of a classical system.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e77331",
   "metadata": {},
   "source": [
    "#### 1.5 Propositions\n",
    "\n",
    "Discussion regarding sets and logical operation such as $\\text{and}$, $\\text{or}$ and $\\text{not}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fae1565",
   "metadata": {},
   "source": [
    "#### 1.6 Testing Classical Propositions\n",
    "\n",
    "Let's return to the simple quantum system consisting of a single spin, and the various propositions whose truth we could test using the earlier apparatus. Consider following propositions:\n",
    "\n",
    " - A: The $z$ component of the spin is $+1$.   \n",
    " - B: The $x$ component of the spin is $+1$.\n",
    " \n",
    "Now consider the following composite proposition:\n",
    "\n",
    "(A $\\text{or}$ B): The $z$ component of the spin is $+1$ $\\text{or}$ the $x$ component of the spin is $+1$.\n",
    "\n",
    "If spins behaved classically, we would first measure $\\sigma_z$. If it is $+1$, the proposition (A $\\text{or}$ B) is true. If $\\sigma_z$ turns out to be $-1$, we then measure the value of $\\sigma_x$. Note that we first tested proposition $A$ followed by proposition $B$. Since we assumed that spins are behaving classically, we could first test proposition $B$ and then $A$. This means it doesn't matter if we test (A $\\text{or}$ B) or (B $\\text{or}$ A), the result will be the same. The reason for this is that measurements can be arbitrary gentle - so gentle that they do not affect the results of subsequent measurements. Therefore, the proposition (A $\\text{or}$ B) has the same meaning as the proposition (B $\\text{or}$ A):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10f1a0",
   "metadata": {},
   "source": [
    "#### 1.7 Testing Quantum Propositions\n",
    "\n",
    "Assume someone unknown to us has secretely prepared a spin in the $\\sigma_z=+1$ state. Now we want to test the proposition (A $\\text{or}$ B). We begin by measuring $\\sigma_z$. Since someone has already set things up, we would find that $\\sigma_z=+1$ and this means that (A $\\text{or}$ B) is true. We now don't have to test $\\sigma_x$ but we would test it just to see what happens. The answer is unpredictable. We randomly find that $\\sigma_x=+1$ or $\\sigma_x=-1$. But neither of these outcomes affects the truth of proposition (A $\\text{or}$ B).\n",
    "\n",
    "But what if we test proposition (B $\\text{or}$ A) by measuring $\\sigma_x$ first? Becasuse the unknown agent set the spin to $+1$ along the $z$ axis, the measurement of $\\sigma_x$ is random. If $\\sigma_x=+1$, proposition (B $\\text{or}$ A) is true. But what if $\\sigma_x=-1$?\n",
    "\n",
    "Let's pause here briefly, to make sure we understand what just happened. As a result of our first measurement, the spin is no longer in its original state $\\sigma_z=+1$. It is in a new state, which is either $\\sigma_x=+1$ or $\\sigma_x=-1$. Please take a moment to let this idea sink in. We cannot overstate its importance.  \n",
    "\n",
    "\n",
    "Back to our experiment. We measured $\\sigma_x=-1$. This means we have to test second half of proposition in (B $\\text{or}$ A). For this, we have to measure $\\sigma_Z$. According to quantum mechanics, the result will be randomly $\\pm1$. This means that there is a 25 percent probability that the experiment produces $\\sigma_x-1$ and $\\sigma_z-1$. In other words, with a probability of $\\frac{1}{4}$, we find that (B $\\text{or}$ A) is false; this occurs despite the fact the hidden agent had originally made sure that $\\sigma_z=+1$.\n",
    "\n",
    "So, in quantum mechanics, the truth of (A $\\text{or}$ B) may depend on the order in which we confirm the two propositions. This is not a small thing; it means not only that the laws of quantum physics are different from their classical couterparts, but that the very foundations of logic are different in quantum physics as well. \n",
    "\n",
    "Forget (B $\\text{or}$ A). What about (A $\\text{or}$ B)? Earlier we first tested proposition **A** and then proposition **B** (we tested **B** out of curiosity). What if we test **A** again? Quantum mechanically, the second measurement ($\\sigma_x=\\pm1$) ruins the possibility of verifying the first ($\\sigma_z$). Once $\\sigma_x$ has been prepared along the $x$ axis, another measurement of $\\sigma_z$ will give a random answer. Thus (A $\\text{or}$ B) is not confirmable.\n",
    "\n",
    "This is an illustration of uncertainty principle. The uncertaintly principle applies to many pairs of measurable quantities, including momentum-position pair. In the case of position and momentum, the two propositions we might consider are:\n",
    "\n",
    " - A certain particle has position $x$. \n",
    " - That same particle has momentum $p$\n",
    "\n",
    "From these, we can form the two composite propositions\n",
    "\n",
    " - The particle has position $x$ $\\text{and}$ the particle has momentum $p$.\n",
    " - The particle has position $x$ $\\text{or}$ the particle has momentum $p$.\n",
    " \n",
    "Both of these propositions have meaning in the English language, and in classical physics as well. However,in quantum physics, the first of thse propositions is meaningless, much less wrong. And second proposition means something quite different from what we might think. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b0f91",
   "metadata": {},
   "source": [
    "#### 1.8 Mathematical Interlude: Complex Numbers\n",
    "\n",
    "skipped "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa43b0",
   "metadata": {},
   "source": [
    "#### 1.9 Mathematical Interlude: Vector Spaces\n",
    "\n",
    "For a classical system, the space of states is a set (of possible states), and the logic is Boolean. The space of states in quantum mechanics is not a mathematical set; it is a **vector space**. \n",
    "\n",
    "The vector spaces we use to define quantum mechanical states are called **Hilbert spaces**. When you come across the term Hilbert space in quantum mechanics, it refers to the space of states. A Hilbert space may  have either a finite or an infinite number of dimensions. \n",
    "\n",
    "In QM, a vector space is composed of elements $|{A}\\rangle$ called **ket-vectors** or just **kets**. Here are the axioms we will use to define the vector space of states of a quantum system ($z$ and $w$ are complex numbers):\n",
    "\n",
    "\n",
    " - The sum of two kets is also a ket:\n",
    " \n",
    " $|{A}\\rangle +|{B}\\rangle=|{C}\\rangle$\n",
    "\n",
    "\n",
    " - Vector addition is commutative\n",
    " \n",
    " $|{A}\\rangle +|{B}\\rangle=|{B}\\rangle +|{A}\\rangle$\n",
    "\n",
    "\n",
    " - Vector addition is associative:\n",
    " \n",
    " $(|{A}\\rangle +|{B}\\rangle) +|{C}\\rangle = |{A}\\rangle +(|{B}\\rangle +|{C}\\rangle)  $\n",
    "\n",
    "\n",
    " - There is a unique vector 0 such that when you add it any ket, it gives the same ket back: \n",
    " \n",
    " $|{A}\\rangle + 0= |{A}\\rangle$  \n",
    " \n",
    " \n",
    " - Given any ket $|A\\rangle$, there is a unique ket $-|A\\rangle$ such that:\n",
    "  \n",
    "  $|{A}\\rangle +(-|{A}\\rangle) =0$\n",
    "  \n",
    " \n",
    " - ket can be multiplied by a complex number which results in another ket and this multiplication is linear:\n",
    " \n",
    " $|{zA}\\rangle =z|{A}\\rangle=|{B}\\rangle$\n",
    " \n",
    " \n",
    " - The distributive property holds:\n",
    " \n",
    " $z(|{A}\\rangle +|{B}\\rangle)=z|{A}\\rangle+z|{B}\\rangle$ \n",
    " \n",
    " $(z+w)|{A}\\rangle=z|{A}\\rangle+w|{A}\\rangle$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791b5572",
   "metadata": {},
   "source": [
    "##### Functions and Column Vectors\n",
    "\n",
    "Let's look at some concrete examples of complex vector spaces. 2-dimensional column vectors provide one concrete example. we construct them by stacking up a pair of complex numbers, $\\alpha_1$ and $\\alpha_2$, in the form:\n",
    "\n",
    "$$\\begin{pmatrix}\\alpha_1\\\\\\alpha_2\\end{pmatrix}$$\n",
    "\n",
    "and identifying this 'stack' with the ket-vector $|A\\rangle$. The complex numbers  $\\alpha_1$ and $\\alpha_2$ are the components of $|A\\rangle$. You can do something like this:\n",
    "\n",
    "$$\\begin{pmatrix}\\alpha_1\\\\\\alpha_2\\end{pmatrix}+ \\begin{pmatrix}\\beta_1\\\\\\beta_2\\end{pmatrix}=\\begin{pmatrix}\\alpha_1+\\beta_1\\\\\\alpha_2+\\beta_2\\end{pmatrix}$$\n",
    "\n",
    "Moreover, you can multiply the column vector by a complex number $z$ just by multiplying the components:\n",
    "\n",
    "$$z\\begin{pmatrix}\\alpha_1\\\\\\alpha_2\\end{pmatrix}=\\begin{pmatrix}z\\alpha_1\\\\z\\alpha_2\\end{pmatrix}$$\n",
    "\n",
    "Column vector spaces of any number of dimensions can be constructed. For example, here is a 5-dimensional column vector -\n",
    "\n",
    "$$\\begin{pmatrix}\\alpha_1\\\\\\alpha_2\\\\\\alpha_3\\\\\\alpha_4\\\\\\alpha_5\\end{pmatrix}$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748bc63a",
   "metadata": {},
   "source": [
    "\n",
    "##### Bras and Kets\n",
    "\n",
    "We know that a complex number $z$ has its conjugate counterpart, usually dnoted as $z^*$. In the same fashion every ket $|A\\rangle$ has a corresponding **bra**, $\\langle{A}|$, which is conjugate-transpose of the ket $|A\\rangle$. Shortly, we will define inner products of bras and kets, using expressions like $\\langle{A}|B\\rangle$ to form bra-kets or barckets. Inner products are extremely important in the mathematics of QM. \n",
    "\n",
    "Bra vectors satisfy the same axioms as the kets, but there are two things to keep in mind about the correspondence between bras and kets:\n",
    "\n",
    "1. The bra corresponding to \n",
    "\n",
    "$$|A\\rangle+|B\\rangle$$\n",
    "\n",
    "is\n",
    "\n",
    "$$\\langle{A}|+\\langle{B}|$$\n",
    "\n",
    "\n",
    "2. If $z$ is a complex number, then it is not true that the bra corresponding to $z|A\\rangle$ is $\\langle{A}|z$. The bra corresponding to \n",
    "\n",
    "$$z|A\\rangle$$\n",
    "\n",
    "is\n",
    "\n",
    "$$\\langle{A}|z^*$$\n",
    "\n",
    "We saw that kets are represented by column vectors, the dual bra is represented by row vector whose components are complex conjugate of components of corresponding ket. Thus if \n",
    "\n",
    "$$|A\\rangle =\\begin{pmatrix}\\alpha_1\\\\\\alpha_2\\\\\\alpha_3\\\\\\alpha_4\\\\\\alpha_5\\end{pmatrix}$$\n",
    "\n",
    "then \n",
    "\n",
    "$$\\langle{A}|= \\begin{pmatrix}\\alpha_1^*&\\alpha_2^*&\\alpha_3^*&\\alpha_4^*&\\alpha_5^*\\end{pmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681679c8",
   "metadata": {},
   "source": [
    "#### Inner Products\n",
    "\n",
    "Just like dot product defined for ordinary vectors, there is an analogous operation for bras and kets knows as **inner products**. The inner product is always the the product of a bra and a ket and it is written this way:\n",
    "\n",
    "$$\\langle{B}|A\\rangle$$\n",
    "\n",
    "The result of this operation is a complex number. Followings are the axioms - \n",
    "\n",
    " - $\\langle{C}|\\  (|A\\rangle + |B\\rangle) = \\langle{C}|A\\rangle+\\langle{C}|B\\rangle $\n",
    " \n",
    " \n",
    " - $\\langle{B}|A\\rangle = \\langle{A}|B\\rangle^*$\n",
    " \n",
    "When bras and kets are represented by row and column vectors, the inner product is defined in term  \n",
    "\n",
    "$$\\langle{B}|A\\rangle =\\begin{pmatrix}\\beta_1^*&\\beta_2^*&\\beta_3^*&\\beta_4^*&\\beta_5^*\\end{pmatrix}\\begin{pmatrix}\\alpha_1\\\\\\alpha_2\\\\\\alpha_3\\\\\\alpha_4\\\\\\alpha_5\\end{pmatrix}$$\n",
    " \n",
    "\n",
    "\n",
    "$$=\\beta_1^*\\alpha_1+\\beta_2^*\\alpha_2+\\beta_3^*\\alpha_3+\\beta_4^*\\alpha_4+\\beta_5^*\\alpha_5 $$\n",
    "\n",
    "\n",
    "Using the inner product, we can define some concepts that are familiar from ordinary vectors:\n",
    "\n",
    " - **Normalized Vector:** A vector is said to be normalized if its inner product with itself is 1. Normalized vectors satisfy:\n",
    " \n",
    " \n",
    " $$\\langle{A}|A\\rangle=1$$\n",
    " \n",
    "  - **Orthogonal Vectors:** Two vectors are said to be orthogonal if their inner product is zero. $|A\\rangle$ and $|B\\rangle$ are orthogonal if \n",
    "  \n",
    "  \n",
    "  $$\\langle{B}|A\\rangle=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e9f32",
   "metadata": {},
   "source": [
    "#### Orthonormal Bases\n",
    "\n",
    "When working with ordinary 3-D vectors, it is extremely useful to introduce a set of three mutually orthogonal unit vectors (along $x$,$y$ and $z$ axes) and use them as a basis to construct any vector. There is nothing special about the particular axes $x$,$y$ and $z$. As long as the basis vectors are of unit length and are mutually orthogonal, they comprise an **orthonormal basis**.\n",
    "\n",
    "\n",
    "The same principle is true for complex vector spaces. The maximum number of mutually orthogonal vectors is the dimension of the space. For column vectors, the dimension is simply the number of elements in the column. \n",
    "\n",
    "Let's consider an N-dimensional space and a particular orthonormal basis of kets labeled $|i\\rangle$. The label $i$ runs from 1 to N. Consider a vector $|A\\rangle$, written as a sum of basis vectors:\n",
    "\n",
    "$$|A\\rangle=\\sum\\limits_{i}\\alpha_i|i\\rangle \\ \\ \\ \\ \\ \\ eq.1.3$$\n",
    "\n",
    "The $\\alpha_i$ are complex numbers called the components of the vector, and to calculate them we take the inner product of both sides with a basis bra $\\langle{j}|$:\n",
    "\n",
    "$$\\langle{j}|A\\rangle = \\sum\\limits_{i}\\alpha_i\\langle{j}|i\\rangle  \\ \\ \\ \\ \\ \\ eq.1.4$$\n",
    "\n",
    "Next, we use the fact that the basis vectors are orthonormal. This implies that $\\langle{j}|i\\rangle = 0$ if $i$ is not equal to $j$, and $\\langle{j}|i\\rangle = 1$ if $i$ is equal to $j$. In other words, $\\langle{j}|i\\rangle = \\lambda_{ij}$. This gives us:\n",
    "\n",
    "$$\\langle{j}|A\\rangle = \\alpha_j  \\ \\ \\ \\ \\ \\ eq.1.5$$\n",
    "\n",
    "Thus, we see that the components of a vector are just its inner products with the basis vectors. We can rewrite eq 1.3 as:\n",
    "\n",
    "\n",
    "$$|A\\rangle=\\sum\\limits_{i}|i\\rangle\\langle{i}|A\\rangle $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e519de",
   "metadata": {},
   "source": [
    "### Lecture 2: Quantum States"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad3653f",
   "metadata": {},
   "source": [
    "#### 2.1 States and Vectors\n",
    "\n",
    "In classsical physics, knowing *the state of a system* implies knowing everything that is necessary to predict the future of that system. But quantum systems are not completely predictable. Also, quantum states have a different meaning than classical states. Very roughly, knowing a quantum state means knowing *as much as can be known* about how system was prepared. \n",
    "\n",
    "The obvious question to ask is whether the unpredictability is due to an incompleteness in what we call a quanum state. There are various opinions about this matter. Here is a sampling:\n",
    "\n",
    " - Yes, the usual notion of quantum state is incomplete. There are 'hidden variables' that, if only we could access them, would allow complete predictability. May be those variables are hard to measure but in principle they are experimentally available to us. Or maybe hidden variables are simply not detectable. \n",
    " \n",
    " - No, the hidden variables concept does not lead us in a profitable direction. QM is unavoidably unpredictable. QM is as complete a calculas of probabilities as is possible. The job of a physicist is to learn and use this calculas. \n",
    " \n",
    "\n",
    "For practical reasons, we will adopt the second view. In practice, what this means for the quantum spin of Lecture ! is that, when our apparatus acts and tells us that $\\sigma_z=+1$, there is no more to know, or that can be known. Likewise, if we rotate the apparatus and measure $\\sigma_x=+1$, there is no more to know. Likewise for any other component of the spin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb310d",
   "metadata": {},
   "source": [
    "#### 2.2 Representing Spin States\n",
    "\n",
    "Our goal is to build a representation that captures everything we know about the behaviour of spins. At this point, the process will be more intuitive than formal. \n",
    "\n",
    "Let's begin by labelling the possible spin states along the three coordinate axes. Along the $z$ axis, the two possible states that can be prepared correspond to $\\sigma_z=\\pm1$. Let's denote them by kets $|u\\rangle$ and $|d\\rangle$ (as in *up* and *down*). Similarily for $x$ axis, we may write  $\\sigma_x=\\pm1$ and denote thme as $|r\\rangle$ and $|l\\rangle$. For $y$ axis, we have $|i\\rangle$ and $|o\\rangle$ (as in *in* and *out*).\n",
    "\n",
    "The idea that there are no hidden variables has a very simple mathematical representation: the space of states for a single spin has only two dimensions. This point deserve emphasis: *All possible spin states can be represented in a 2-dimensional vector space*.\n",
    "\n",
    "We could, somewhat arbitrarily, choose $|u\\rangle$ and $|d\\rangle$ as the two basis vectors. Actually, the choice is not totally arbitrary. The basis vectors must be orthogonal to each other. Now we can write *any* state as a linear superposition of these two basis vectors. Let's use the symbol $|A\\rangle$ for a generic state. We can write this as an equation:\n",
    "\n",
    "$$|A\\rangle=\\alpha_u|u\\rangle+\\alpha_d|d\\rangle$$\n",
    "\n",
    "where $\\alpha_u$ and $\\alpha_d$ are the components of $|A\\rangle$ along the respective basis vectors. We can also write\n",
    "\n",
    "$$\\alpha_u=\\langle{u}|A\\rangle \\phantom{gdsgfgdf}$$\n",
    "\n",
    "$$\\alpha_d=\\langle{d}|A\\rangle \\ \\ \\ \\ \\ \\ \\ \\ eq.2.1$$\n",
    "\n",
    "Let's see what these equations mean. $|A\\rangle$ can represent any state of the spin, prepared in any manner. The components $\\alpha_u$ and $\\alpha_d$ are complex numbers; by themselves, they have no experimental meaning, but their magnitudes do. In particular, $\\alpha_u^*\\alpha_u$ and $\\alpha_d^*\\alpha_d$ have the following meaning:\n",
    "\n",
    " - Given that the spin has been prepared in the state $|A\\rangle$, and that the appratus is oriented along $z$ axis, the quantity $\\alpha_u^*\\alpha_u$ is the probabiliy that the spin would be measured as $\\sigma_z=+1$. \n",
    " \n",
    " \n",
    " - Likewise $\\alpha_d^*\\alpha_d$ is the probability that $\\sigma_x$ would be *down* if measured. \n",
    " \n",
    "$\\alpha_u$ and $\\alpha_d$ are called probability amplitudes. They are themselves not probabilities. In other words, the probabilities for measurements of *up* and *down* are given by\n",
    "\n",
    "$$P_u=\\langle{A}|u\\rangle\\langle{u}|A\\rangle \\phantom{dfdsfsdf}$$\n",
    "\n",
    "\n",
    "$$P_d=\\langle{A}|d\\rangle\\langle{d}|A\\rangle \\ \\ \\ \\ \\ \\ eq.2.2$$\n",
    "\n",
    "Notice that we have said nothing about what $\\sigma_z$ is before it is measured. Before measurement, all we have is the vector $|A\\rangle$, which represents the potential possibilities but not the actual values of our measurement. \n",
    "\n",
    "Two other points are important: First, note that $|u\\rangle$ and $|d\\rangle$ are mutually orthogonal. In other words,\n",
    "\n",
    "$$\\langle{u}|d\\rangle =0$$\n",
    "\n",
    "$$\\langle{d}|u\\rangle =0$$\n",
    "\n",
    "The physical meaning of this is that, if the spin is prepared *up*, then the probablility to detect it *down* is zero, and vice versa. This point is so important, it has to be repeated again: Two orthogonal states are physically distinct and mutually exclusive. If the spin is in one of these states, it cannot be (has zero probability to be) in the other one.\n",
    "\n",
    "**But don't mistake the orthogonality of state vectors for orthogonal directions in space. In fact, the directions *up* and *down* are not orthogonal directions in space, even though their associated state vectors are orthogonal in state space.**\n",
    "\n",
    "The second important point is that for the total probability to come out equal to unity, we must have:\n",
    "\n",
    "$$\\alpha_u^*\\alpha_u +$\\alpha_d^*\\alpha_d=1$$\n",
    "\n",
    "This is equivalent to saying that the vector $|A\\rangle$ is normalized to a unit vector:\n",
    "\n",
    "$$\\langle{A}|A\\rangle =1$$\n",
    "\n",
    "This is a very general principle of quantum mechanics that extends to all quantum systems: the state of a system is represented by a unit (normalized) vector in a vector space of states. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f857c6d3",
   "metadata": {},
   "source": [
    "#### 2.3 Along the $x$ Axis\n",
    "\n",
    "We said before that we can represent any spin state as a linear combination of the basis vectors $|u\\rangle$ and $|d\\rangle$. Let's that for $|r\\rangle$. We may recall that if apparatus initially prepares $|r\\rangle$, and is then rotated to measure $\\sigma_z$, there will be equal probabilities for *up* and *down*. Thus, $\\alpha_u^*\\alpha_u$ and $\\alpha_d^*\\alpha_d$ must both be equal to $\\frac{1}{2}$. A simple vector that satisfies this rule is:\n",
    "\n",
    "$$|r\\rangle=\\frac{1}{\\sqrt{2}}|u\\rangle +\\frac{1}{\\sqrt{2}}|d\\rangle$$\n",
    "\n",
    "There is some ambiguity in this choice, but as we will see later, it is nothing more than the ambiguity in our choice of exact directions for the $x$ and $y$ axes.\n",
    "\n",
    "Next, let's look at the vector $|l\\rangle$. Here is what we know: when the spin has been prepared in the *left* configuration, the probabilities for $\\sigma_z$ are again equal to $\\frac{1}{2}$, just like before. That is not enough to determine the values of $\\alpha_u^*\\alpha_u$ and $\\alpha_d^*\\alpha_d$, but there is another condition that we can infer. Recall that $|u\\rangle$ and $|d\\rangle$ are orthogonal. The same is true for $|l\\rangle$ and $|r\\rangle$. This means:\n",
    "\n",
    "\n",
    "$$\\langle{l}|r\\rangle =0$$\n",
    "\n",
    "$$\\langle{r}|l\\rangle =0$$\n",
    "\n",
    "This gives us:\n",
    "\n",
    "$$|l\\rangle=\\frac{1}{\\sqrt{2}}|u\\rangle -\\frac{1}{\\sqrt{2}}|d\\rangle$$\n",
    "\n",
    "You might have tempted to say that $|l\\rangle$ should be equal to $|r\\rangle$ but now you can see it wouldn't have satisfied the condition that $|l\\rangle$ and $|r\\rangle$ are orthogonal. \n",
    "\n",
    "Again there some ambiguity in the choice of $|l\\rangle$. This is called the *phase ambiguity*. Suppose we multiply $|l\\rangle$ by a complex number $z$. That will have no effect on whether it is orthogonal to $|r\\rangle$, though in general the result will no longer be normalized (have unit length). But if we choose $z=e^{i\\theta}$ (where $\\theta$ can be any real number), then there will be no effect on normalization because $e^{i\\theta}$ has unit magnitude. In other words, $\\alpha_u^*\\alpha_u +\\alpha_d^*\\alpha_d=1$ will hold true. Since a number of the form $z=e^{i\\theta}$ is called a phase-factor, the ambiguity is called the phase ambiguity. Later, we will find out that no measurable quantity is sensitive to the overall phase-factor, and therefore we can ignore it when specifying states. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef507df",
   "metadata": {},
   "source": [
    "#### 2.4 Along the $y$ Axis\n",
    "\n",
    "Finally this brings us to $|i\\rangle$ and $|o\\rangle$. Let's look at the conditions they need to satisfy. First:\n",
    "\n",
    "$$\\langle{i}|o\\rangle=0$$\n",
    "\n",
    "Above should be obvious to see. There are additional restrictions on the vector $|i\\rangle$ and $|o\\rangle$. Using the relationships expressed in Eq. 2.1 and 2.2, and the statstical results from our experiments, we can write the following:\n",
    "\n",
    "$$\\langle{o}|u\\rangle\\langle{u}|o\\rangle=\\frac{1}{2}$$\n",
    "$$\\langle{o}|d\\rangle\\langle{d}|o\\rangle=\\frac{1}{2}$$\n",
    "$$\\langle{i}|u\\rangle\\langle{u}|i\\rangle=\\frac{1}{2}$$\n",
    "$$\\langle{i}|d\\rangle\\langle{d}|i\\rangle=\\frac{1}{2}$$\n",
    "\n",
    "In the first two equations, $|o\\rangle$ takes the role of $|A\\rangle$ from Eq. 2.1 and 2.2. In the second two, $|i\\rangle$ takes that role. These conditions state that if the spin is oriented along $y$, and is then measured along $z$, it is equally likely to be *up* and *down*. We should also expect that if the spin were measured along the $x$, it would be equally likely to be *right* or *left*. This leads to additional conditions:\n",
    "\n",
    "$$\\langle{o}|r\\rangle\\langle{r}|o\\rangle=\\frac{1}{2}$$\n",
    "$$\\langle{o}|l\\rangle\\langle{l}|o\\rangle=\\frac{1}{2}$$\n",
    "$$\\langle{i}|r\\rangle\\langle{r}|i\\rangle=\\frac{1}{2}$$\n",
    "$$\\langle{i}|l\\rangle\\langle{l}|i\\rangle=\\frac{1}{2}$$\n",
    "\n",
    "These conditions are sufficient to determine the form of the vectors $|i\\rangle$ and $|o\\rangle$, apart from phase ambiguity. Doing some maths will give us:\n",
    "\n",
    "\n",
    "$$|i\\rangle=\\frac{1}{\\sqrt{2}}|u\\rangle +\\frac{i}{\\sqrt{2}}|d\\rangle$$\n",
    "$$|o\\rangle=\\frac{1}{\\sqrt{2}}|u\\rangle -\\frac{i}{\\sqrt{2}}|d\\rangle$$\n",
    "\n",
    "Note - refer to page 44-45. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da14ba",
   "metadata": {},
   "source": [
    "#### 2.5 Counting Parameters\n",
    "\n",
    "It's always important to know many independent parameters it takes to characterize a system. The general spin state is defined by two complex numbers, $\\alpha_u$ and $\\alpha_d$. That seems to add up to four real parameters, with each complex parameter counting as two real ones. But recall that the vector has to be normalized ($\\alpha_u^*\\alpha_u +\\alpha_d^*\\alpha_d=1$). The normalization condition gives us one equation involving real variables, and cuts the number of parameters down to three. \n",
    "\n",
    "We also mentioned that the physical properties of a state-vector do not depend on the overall phase-factor. This means that one of the three remaining parameters is redundant, leaving only two. (See [this link](https://physics.stackexchange.com/questions/205881/how-many-parameters-are-needed-to-specify-a-quantum-state) also for better explanation). Thus, there is enough freedom in the expression \n",
    "\n",
    "$$\\alpha_u|u\\rangle+\\alpha_d|d\\rangle$$ \n",
    "\n",
    "\n",
    "to describe all the possible orientations of a spin, even though there are only two possible outcomes of an experiment along any axis. \n",
    "\n",
    "Note: Need to understand this section better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59fd3d3",
   "metadata": {},
   "source": [
    "#### 2.6 Representing Spin States as Column Vectors\n",
    "\n",
    "Soon we will need to perform detailed calculations on spin states, and for that we'll need to write our state-vectorsf in column form. Because of \"phase-indifference,\" the column representations are not unique, and we'll try to choose the simplest and most convenient ones  we can find. \n",
    "\n",
    "As ususal, we'll start with $|u\\rangle$ and $|d\\rangle$. We need them to have unit length, and to be mutually orthogonal. A pair of columns that satisfies these requirements is \n",
    "\n",
    "\n",
    "$$|u\\rangle=\\begin{pmatrix}1\\\\0\\end{pmatrix}$$\n",
    "\n",
    "$$|d\\rangle=\\begin{pmatrix}0\\\\1\\end{pmatrix}$$\n",
    "\n",
    "With these column vectors, it will be easy to create column vectors for $|r\\rangle$, $|l\\rangle$, $|i\\rangle$ and $|o\\rangle$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe65e268",
   "metadata": {},
   "source": [
    "### Lecture 3: Principles of Quantum Mechanics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32243eb4",
   "metadata": {},
   "source": [
    "#### 3.1 Mathematical Interlude: Linear Operators\n",
    "\n",
    "**Machines and Matrices**\n",
    "\n",
    "States in QM are mathematically described as vectors in a vector space. Physical observables - the things that you can measure - are described by linear operators. We'll see later that operators corresponding to physical observables must be Hermitian as well as linear. The correspondence between operators and observables is subtle, and understanding it will take some effort. \n",
    "\n",
    "Observables are also associated with a vector space, but they are not state-vectors. They are the things you measure-$\\sigma_x$ would be an example-and they are represented by *linear operators*. Think of them as a machine which takes a vector $|A\\rangle$ as input and gives $|B\\rangle$ as output. \n",
    "\n",
    "Let's denote the operator by $\\text{M}$. Here is the equation to express the fact that $\\text{M}$ acts on the vector $|A\\rangle$ to give $|B\\rangle$:\n",
    "\n",
    "$$\\text{M}|A\\rangle=|B\\rangle$$\n",
    "\n",
    "Not every machine is a *linear operator*. Linearity implies a few simple properties. To begin with, a linear operator must give a unique output for every vector in the space. \n",
    "\n",
    "The next property states that when a linear operator $\\text{M}$ acts on a multiple of an input vector, it gives the same multiple of the output vector. Thus, if $\\text{M}|A\\rangle=|B\\rangle$, and $z$ is any complex number, then\n",
    "\n",
    "$$\\text{M}z|A\\rangle=z|B\\rangle$$\n",
    "\n",
    "The only other rule is that, when $\\text{M}$ acts on a sum of vectors, the results are simply added together:\n",
    "\n",
    "$$\\text{M}(|A\\rangle+|B\\rangle)=\\text{M}|A\\rangle+\\text{M}|B\\rangle$$\n",
    "\n",
    "We are now going to take the equation\n",
    "\n",
    "$$\\text{M}|A\\rangle=|B\\rangle$$\n",
    "\n",
    "and write in component form. From first chapter, we have\n",
    "\n",
    "$$|A\\rangle=\\sum\\limits_j\\alpha_j|j\\rangle$$\n",
    "\n",
    "Here, we're using $j$ to avoid confusion with *in* spin. Now, we'll represent $|B\\rangle$ in the same way and plug both of these substitutions into $\\text{M}|A\\rangle=|B\\rangle$. That gives\n",
    "\n",
    "$$\\sum\\limits_{j}M|j\\rangle\\alpha_j=\\sum\\limits_j\\beta_j|j\\rangle$$\n",
    "\n",
    "The last step is to take the inner product of both sides with a particular basis vector $\\langle{k}|$ (note that it is a bra), resulting in\n",
    "\n",
    "$$\\sum\\limits_{j}\\langle{k}|M|j\\rangle\\alpha_j=\\sum\\limits_j\\beta_j\\langle{k}|j\\rangle \\ \\ \\ \\ 3.1$$\n",
    "\n",
    "To make sense of this result, remember that $\\langle{k}|j\\rangle$ is zero if $j$ and $k$ are not equal, 1 if they are equal. That means the sum on the right side collapses to a single term, $\\beta_k$.\n",
    "\n",
    "On the left side, we see a set of quantities $\\langle{k}|M|j\\rangle\\alpha_j$. We can abbreviate $\\langle{k}|M|j\\rangle$ with the symbol $m_{kj}$. Notice that each $m_{kj}$ is just a complex number. To see why, think of $\\text{M}$ operating on $|j\\rangle$ to give a new ket. The inner product of $\\langle{k}|$ with this new ket must be a complex number. The quantities $m_{kj}$ are called the *matrix elements* $\\text{M}$ and are often arranged into a square *n x n* matrix. For n=3, we can write the symbolic equation\n",
    "\n",
    "$$\\text{M} = \\begin{pmatrix} m_{11}&m_{12}&m_{13}\\\\m_{21}&m_{22}&m_{23}\\\\m_{31}&m_{32}&m_{33}\\\\               \\end{pmatrix}$$\n",
    "\n",
    "We now rewrite eq 3.1 as \n",
    "\n",
    "$$\\sum\\limits_{j}m_{kj}\\alpha_j= \\beta_k$$\n",
    "\n",
    "We can write this in matrix form as well\n",
    "\n",
    "$$\\begin{pmatrix} m_{11}&m_{12}&m_{13}\\\\m_{21}&m_{22}&m_{23}\\\\m_{31}&m_{32}&m_{33}\\end{pmatrix}\\begin{pmatrix}\\alpha_1\\\\\\alpha_2\\\\\\alpha_3\\end{pmatrix}=\\begin{pmatrix}\\beta_1\\\\\\beta_2\\\\\\beta_3\\end{pmatrix}$$\n",
    "\n",
    "Familiarity with matrix multiplication is assumed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442553b6",
   "metadata": {},
   "source": [
    "#### 3.1.2 Eigenvalues and Eigenvectors\n",
    "\n",
    "In general, when a linear operator acts on a vector, it will change the direction of the vector. This means that what comes out of the machine will not just be the input vector multiplied by a number. But for a particular linear operator, there will be certain vectors whose directions are the same when they come out as they were wheb they went in. These special vectors are called **eigenvectors**. The definition of an eigenvector of $\\text{M}$ is a vector $|\\lambda\\rangle$ such that\n",
    "\n",
    "\n",
    "$$\\text{M}|\\lambda\\rangle=\\lambda|\\lambda\\rangle$$\n",
    "\n",
    "Don't get confused with, the double use of $\\lambda$. $\\lambda$ (as opposed to $|\\lambda\\rangle$) is a number - generally a complex one. The ket $|\\lambda\\rangle$ has special relationship with $\\text{M}$. When $|\\lambda\\rangle$ is fed into the machine $\\text{M}$, all that happens is that it gets multiplied by the number $\\lambda$. For example, if $\\text{M}$ is \n",
    "\n",
    "$$\\begin{pmatrix}1&2\\\\2&1\\end{pmatrix}$$\n",
    "\n",
    "and $|\\lambda\\rangle$ is\n",
    "\n",
    "$$\\begin{pmatrix}1\\\\1\\end{pmatrix}$$\n",
    "\n",
    "Then result is $|\\lambda\\rangle$ multiplied by 3. $\\text{M}$ also happens to have another eigenvector (verify yourself): \n",
    "\n",
    "$$\\begin{pmatrix}1\\\\-1\\end{pmatrix}$$\n",
    "\n",
    "Just as the vectors that get multiplied by numbers when $\\text{M}$ acts on them are called eigenvectors of $\\text{M}$, the constants that multiply them are called **eigenvalues**. In general, the eigenvalues are complex numbers. For the $\\text{M}$ in above example, 3 and -1 are its eigenvalues. \n",
    "\n",
    "Linear operators can also act on bra-vectors. The notation for multiplying $\\langle{B}|$ by $\\text{M}$ is \n",
    "\n",
    "$$\\langle{B}|\\text{M}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9bea56",
   "metadata": {},
   "source": [
    "#### 3.1.3 Hermitian Conjugation\n",
    "\n",
    "You might think that if $\\text{M}|A\\rangle=|B\\rangle$ then $\\langle{A}|\\text{M}=\\langle{B}|$ but that would be wrong. Recall that if $z|A\\rangle=|B\\rangle$, then $\\langle{A}|z^*=\\langle{B}|$. Similarlity, what we need is a concept of complex conjugation for operators. Let's look at the equation $\\text{M}|A\\rangle=|B\\rangle$ in component notation,\n",
    "\n",
    "$$\\sum\\limits_{i}m_{ji}\\alpha_i=\\beta_j$$\n",
    "\n",
    "and form its complex conjugate,\n",
    "\n",
    "$$\\sum\\limits_{i}m^*_{ji}\\alpha^*_i=\\beta^*_j$$\n",
    "\n",
    "We would like to write this equation in matrix form, using bras instead of kets. For the result to work out correctly, we also need to rearrange the complex conjugate elements of matrix $\\text{M}$. The notation for this rearrangement is $\\text{M}^\\dagger$, as explained below. Our new equation is\n",
    "\n",
    "\n",
    "$$\\langle{A}|\\text{M}^\\dagger=\\begin{pmatrix}\\alpha_1^*&\\alpha_2^*&\\alpha_3^*\\end{pmatrix} \\begin{pmatrix}m_{11}^* & m_{21}^* & m_{31}^* \\\\m_{12}^* & m_{22}^* & m_{32}^*\\\\m_{13}^* & m_{23}^* & m_{33}^* \\end{pmatrix}$$\n",
    "\n",
    "Note carefully that the matrix representing $\\text{M}^\\dagger$ is conjugate-transpose of matrix representing $\\text{M}$.\n",
    "\n",
    "The complex conjugate of a transposed matrix is called its *Hermitian conjugate* denoted by a dagger. In symbols,\n",
    "\n",
    "$$\\text{M}^\\dagger=[\\text{M}^T]^*$$\n",
    "\n",
    "To summarize: if $\\text{M}$ acts on the ket $|A\\rangle$ to give $|B\\rangle$,  then it follows that $\\text{M}^\\dagger$ acts on the bra $\\langle{A}|$ to give $\\langle{B}|$. In symbols:\n",
    "\n",
    "If \n",
    "\n",
    "$$\\text{M}|A\\rangle=|B\\rangle$$\n",
    "\n",
    "then \n",
    "\n",
    "$$\\langle{A}|\\text{M}^\\dagger  =\\langle{B}|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6823fde0",
   "metadata": {},
   "source": [
    "#### 3.1.4 Hermitian Operators\n",
    "\n",
    "Oservables in QM are represented by linear operators that are equal to their own Hermitian conjugates. They are called *Hermitian operators*. Hermitian operators satisfy the property\n",
    "\n",
    "$$\\text{M}=\\text{M}^\\dagger$$\n",
    "\n",
    "In terms of matrix elements,  this can be stated as\n",
    "\n",
    "$$m_{ji}=m^*_{ij}$$\n",
    "\n",
    "Hermitian operators (and matrices) have some special properties. The first is that their eigenvalues are all real. Let's prove it.\n",
    "\n",
    "Suppose $\\lambda$ and $|\\lambda\\rangle$ represent an eigenvalue and the corresponding eigenvector of the Hermitian operator $\\text{L}$. In symbols,\n",
    "\n",
    "$$\\text{L}|\\lambda\\rangle=\\lambda|\\lambda\\rangle$$\n",
    "\n",
    "Then, by the definition of Hermitian conjugation,\n",
    "\n",
    "$$\\langle\\lambda|\\text{L}^\\dagger=\\langle\\lambda|\\lambda^*$$\n",
    "\n",
    "However, since $\\text{L}$ is Hermitian, it is equal to $\\text{L}^\\dagger$. Thus, we can rewrite the equation as \n",
    "\n",
    "$$\\text{L}|\\lambda\\rangle=\\lambda|\\lambda\\rangle$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\langle\\lambda|\\text{L}=\\langle\\lambda|\\lambda^*$$\n",
    "\n",
    "Now multipljy first of above two eq by $\\langle\\lambda|$ and other by $|\\lambda\\rangle$. They become\n",
    "\n",
    "$$\\langle\\lambda|\\text{L}|\\lambda\\rangle=\\lambda\\langle\\lambda|\\lambda\\rangle$$\n",
    "\n",
    "and \n",
    "\n",
    "\n",
    "$$\\langle\\lambda|\\text{L}|\\lambda\\rangle=\\lambda^*\\langle\\lambda|\\lambda\\rangle$$\n",
    "\n",
    "Obviously, for both equations to be true, $\\lambda$ must equal $\\lambda^*$. This means $\\lambda$ must be real. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44c0f0",
   "metadata": {},
   "source": [
    "#### 3.1.5 Hermitian Operators and Orthonnormal Bases\n",
    "\n",
    "We come now to the basic mathematical theorem-I will call it the *fundamental theorem*- that serves as a foundation of QM. The basic idea is that **observable quantities in quantum mechanics are represented  by Hermitian operators.** It's a very simple theorem, but it's an extremely important one. We can state it more precisely as follows:\n",
    "\n",
    "**The Fundamental Theorem**\n",
    "\n",
    " - The eigenvectors of a Hermitian operator are a complete set. This means that **any vector the operator can generate** can be expanded as a sum of its eigenvectors.\n",
    " \n",
    " \n",
    " - If $\\lambda_1$ and $\\lambda_2$ are two unequal eigenvalues of a Hermitian operator, then the corresponding eigenvectors are orthogonal. \n",
    " \n",
    " \n",
    " - Even if the two eigenvalues are equal, the corresponding eigenvectors can be chosen to be orthogonal. This situation, where two different eigenvectors have the same eigenvalue, has a name: it's called *degeneracy*. Degeneracy comes into play when two operators have simultaneous eigenvectors, as discussed later on in chapter 5.\n",
    " \n",
    "One can summarize the fundamental theorem as follows: The eigenvectors of a Hermitian operator form an orthonormal basis. Let's prove it, beginning with the second bullet item. \n",
    "\n",
    "According to the difinition of eigenvectors and eigenvalues, we can write\n",
    "\n",
    "$$\\text{L}|\\lambda_1\\rangle=\\lambda_1|\\lambda_1\\rangle$$\n",
    "$$\\text{L}|\\lambda_2\\rangle=\\lambda_2|\\lambda_2\\rangle$$\n",
    "\n",
    "Now, using the fact that $\\text{L}$ is Hermitian (its own Hermitian conjugate), we can flip the first equation into a bra equation. Thus,\n",
    "\n",
    "$$\\langle\\lambda_1|\\text{L}=\\lambda_1\\langle\\lambda_1|$$\n",
    "$$\\text{L}|\\lambda_2\\rangle=\\lambda_2|\\lambda_2\\rangle$$\n",
    "\n",
    "Now, take the first eq and form its inner product with $|\\lambda_2\\rangle$ and then take the second eq and form  its inner product with $|\\lambda_1\\rangle$. The result is\n",
    "\n",
    "$$\\langle\\lambda_1|\\text{L}|\\lambda_2\\rangle=\\lambda_1\\langle\\lambda_1|\\lambda_2\\rangle$$\n",
    "$$\\langle\\lambda_1|\\text{L}|\\lambda_2\\rangle=\\lambda_2\\langle\\lambda_1|\\lambda_2\\rangle$$\n",
    "\n",
    "By subtracting, we get\n",
    "\n",
    "$$(\\lambda_1-\\lambda_2)\\langle\\lambda_1|\\lambda_2\\rangle=0$$\n",
    "\n",
    "Therefore, if $\\lambda_1$ and $\\lambda_2$ are different, the inner product $\\langle\\lambda_1|\\lambda_2\\rangle$ must be zero. In other words, the two eigenvectors must be orthogonal. \n",
    "\n",
    "Next, let's prove that even if $\\lambda_1=\\lambda_2$, the two eigenvectors can be chosen to be orthogonal. Suppose\n",
    "\n",
    "$$\\text{L}|\\lambda_1\\rangle=\\lambda|\\lambda_1\\rangle$$\n",
    "$$\\text{L}|\\lambda_2\\rangle=\\lambda|\\lambda_2\\rangle$$\n",
    "\n",
    "In other words, there are two distinct eigenvectors with the same eigenvalue. It should be clear that any linear combination of the two eigenvectors is also an eigenvector with the same eigenvalue(?). With this much freedom, it is always possible to find two orthogonal linear combinations. Let's see how. Consider an arbitrary linear combination of these two eigenvectors:\n",
    "\n",
    "$$|A\\rangle=\\alpha|\\lambda_1\\rangle + \\beta|\\lambda_2\\rangle$$\n",
    "\n",
    "Operating on both sides with $\\text{L}$, we get\n",
    "\n",
    "$$\\text{L}|A\\rangle=\\alpha\\text{L}|\\lambda_1\\rangle+\\beta\\text{L}|\\lambda_2\\rangle$$\n",
    "$$\\text{L}|A\\rangle=\\alpha\\lambda|\\lambda_1\\rangle+\\beta\\lambda|\\lambda_2\\rangle$$\n",
    "\n",
    "and finally\n",
    "\n",
    "$$\\text{L}|A\\rangle=\\lambda(\\alpha|\\lambda_1\\rangle+\\beta|\\lambda_2\\rangle)=\\lambda|A\\rangle$$\n",
    "\n",
    "This equation demonstrates that any linear combination of $|\\lambda_1$ and $|\\lambda_2\\rangle$ is also an eigenvector of $\\text{L}$, with the same eigenvalue. By assumption, these two vectors are linearly independent-otherwise, they would not represent distinct states. We will also suppose that they span the subspace of eigenvectors of $\\text{L}$ that have eigenvalue $\\lambda$. There is a process, called the *Gram-Schmidt* procedure, for finding an orthonormal basis for a subspace, given a set of independent vectors that spans the subspace. In plain English, we can find two orthonormal eigenvectors by writing them as a linear combination of $|\\lambda_1$ and $|\\lambda_2\\rangle$. We outline the Gram-Schmidt procedure in next section.\n",
    "\n",
    "The final part of the theorem states that the eigenvectors are complete. In other words, if the space is N-dimensional, there will be N orthonormal eigenvectors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7362ce",
   "metadata": {},
   "source": [
    "#### The Gram-Schmidt Procedure\n",
    "\n",
    "Sometimes we encounter a set of linearly independent eigenvectors that *do not* form an orthonormal set. This typically happens when a system has degenerate states-distinct states that have the same eigenvalue. In this situation, we can always use the linearly independent vectors we have, to create an orthonormal set that spans the same space. \n",
    "\n",
    "Figure shown below illustrate how it works for the simple case of two linearly independent vectors. \n",
    "\n",
    "--image to be inserted\n",
    "\n",
    "-- method detail skipped. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937261ac",
   "metadata": {},
   "source": [
    "### 3.2 The Principles\n",
    "\n",
    "We are now fully prepared to state the principles of quantum mechanics, so without further ado, let's do it. \n",
    "\n",
    "The principles all involve the idea of an observable, and they presuppose the existence of an underlying complex vector space whose vectors represent system states. Here, we present the four principles that do not involve the evolution of state-vectors with time. In Lecture 4, we will add a fifth principle that addresses the time development of system states. \n",
    "\n",
    "An observable could also be called measureable. It's a thing that you can measure with a suitable apparatus. Earlier, we spoke about measuring the components of a spin (such as $\\sigma_x$). These are examples of observables. Let's look at the principles:\n",
    "\n",
    " - Principle 1: The observable or measurable quantities of quantum mechanics are represented by linear operators $\\text{L}$. We'll soon see that $\\text{L}$ must also be Hermitian.\n",
    " \n",
    " \n",
    " - Principle 2: The possible results of a measurement are the eigenvalues of the operator that represents the observable. We'll call these eigenvalues $\\lambda_i$. The state for which the result of a measurement is unambiguously $\\lambda_i$ is the corresponding eigenvector $|\\lambda_i\\rangle$. \n",
    " \n",
    " \n",
    " - Principle 3: Unambiguously distinguishable states are represented by orthogonal vectors. \n",
    " \n",
    " \n",
    " - Principle 4: If $|A\\rangle$ is the state vector of a system, and the observable $\\text{L}$ is measured, the probability to observe value $\\lambda_i$ is \n",
    " \n",
    " \n",
    " $$P(\\lambda_i)=\\langle{A}|\\lambda_i\\rangle\\langle\\lambda_i|A\\rangle$$\n",
    " \n",
    " Note that the $\\lambda_i$ are the eigenvalues of $\\text(L)$, and $|\\lambda_i\\rangle$ are the corresponding eigenvectors. \n",
    " \n",
    " We should note that an operator is a way of packaging up states along with their eigenvalues, which are the possible results of measuring those states. Let's recall some important points from our earlier discussion of spins. First,  the results of a measurement is generally statistically uncertain. However, for any given observable, there are particular states for which the result is absolutely certain. For example,if the spin-measuring apparatus $\\text(A)$ is oriented along  the $z$ axis, the state $|u\\rangle$ always leads to the value  $\\sigma_z=+1$. Principle $1$ gives us a new way to look at these facts. It implies that each obsrvable ($\\sigma_z$, $\\sigma_y$ and $\\sigma_x$) is identified with a specific linear operator in the two dimensional space of states describing the spin. \n",
    "\n",
    "Principle $2$ defines the relation between the operator representing an observable and the possible numerical outputs of the measurement. Namely, the result of a measurement is always one of the eigenvalues of the corresponding opertor. Thus, each component of the spin operator must have two eigenvalues equal to $\\pm1$. \n",
    "\n",
    "Principle $3$ is the most interesting. It speaks of *unambiguous distinct states*, a key idea that we have already encountered. Two states are physically distinct if there is a measurement that can tell them apart without ambiguity. For example, $|u\\rangle$ and $|d\\rangle$ can be distinguished by measuring $\\sigma_z$. If you are handed a spin and told that it is either in the state $|u\\rangle$ or the state $|d\\rangle$, to find out which of the two states is the right one, all you have to do is align $\\text(A)$ with the $z$ axis and measure $\\sigma_z$. There is no possibility of a mistake. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b7636a",
   "metadata": {},
   "source": [
    "But suppose instead that you are told the spin is in one of the two states, $|u\\rangle$ or $|r\\rangle$. There is nothing you can measure that will unambiguously tell you the spin's true state. Measuring $\\sigma_z$ won't do it. If you get $\\sigma_z =+1$, it is possible that the initial state was $|r\\rangle$ since there is a 50% probability of getting this answer in the state $|r\\rangle$. For this reason, $|u\\rangle$ and $|d\\rangle$ are said to be physically distinguishable but $|u\\rangle$ and $|r\\rangle$ are not. Sometimes inner product is called the *overlap*. Principle 3 requires physically distinct states to be represented by orthogonal state-vectors, that is, vectors with no overlap. Thus, for spin states, $\\langle{u}|d\\rangle$ is $0$ but $\\langle{u}|r\\rangle$ is $\\frac{1}{\\sqrt{2}}$.\n",
    "\n",
    "Finally, Principle 4 quantifies these ideas in a rule that expresses the probabilities for various outcomes of an experiment. If we assume that a system has been prepared in state $|A\\rangle$, and subsequently the observable $\\text{L}$ is measured, then the outcome will be one of the eigenvalues $\\lambda_i$ of the opearator $\\text{L}$. But, in general, there is no way to tell for certain which of these values will be observed. There is only a probability-let us call it $P(\\lambda_i)$-that the outcome will be $\\lambda_i$. Principle 4 tells us how to calculate that probability, and it is expressed in terms of the overlap of $|A\\rangle$ and $|\\lambda_i\\rangle$. More precisely, the probability is the square of the magnitude of the overlap:\n",
    "\n",
    "$$P(\\lambda_i)={|\\langle{A}|\\lambda_i\\rangle|}^2$$\n",
    "\n",
    "or, equivalently,\n",
    "\n",
    "$$P(\\lambda_i)=\\langle{A}|\\lambda_i\\rangle\\langle{\\lambda_i}|A\\rangle$$\n",
    "\n",
    "An important consequence of the principles is as follows:\n",
    "\n",
    "*The operators that represent observables are Hermitian.*\n",
    "\n",
    "The reason is twofold. First, since the result of an experiment must be a real number, the eigenvalues of an operator $\\text{L}$ must also be real. Secondly, the eigenvectors that represent unambigiously distinguishable results must have different eigenvalues, and must also be orthogonal. These conditions are sufficient to prove that $\\text{L}$ must be Hermitian. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5574d8",
   "metadata": {},
   "source": [
    "### 3.3 An Example: Spin Operators\n",
    "\n",
    "Our goal in this section is to write down the spin operators in concrete form, as 2 x 2 matrices. Then, we'll get to see how they work in specific situations. \n",
    "\n",
    "Note that, in physical terms, just as a spin-measuring apparatus can only *answer questions* abouta spin's orientation in a specific direction, a spin operator can only provide information about the spin component in a specific direction. The same idea applies to the spin operator - if we want it to tell us about the spin component in a new direction, it too must be 'rotated', but this kind of rotation is accomplished mathematically. The bottom line is that there is a spin operator for each direction in which the apparatus can be oriented. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac21b9c6",
   "metadata": {},
   "source": [
    "### 3.4 Constructing spin Operators\n",
    "\n",
    "The first goal is to construct operators to represent the components of spin $\\sigma_x$, $\\sigma_y$ and $\\sigma_z$. Then we'll build on those results to construct an operator that represents a spin component in any direction. As usual, we begin with $\\sigma_z$. We know that $\\sigma_z$ has definite, ambiguous values for the states $|u\\rangle$ and $|d\\rangle$, and that the corresponding measurement values are $\\sigma_z=+1$ and $\\sigma_z=-1$. Here is what the first three principles tell us:\n",
    "\n",
    " - Principle 1: Each component of $\\sigma$ is represented by a linear operator.\n",
    " \n",
    " \n",
    " - Principle 2: The eigenvectors of $\\sigma_z$ are $|u\\rangle$ and $|d\\rangle$. The corresponding eigenvalues are $+1$ and $-1$. We can express this with the abstract equations\n",
    " \n",
    "$$\\sigma_z|u\\rangle =|u\\rangle$$ \n",
    "\n",
    "$$\\sigma_z|d\\rangle = -|d\\rangle$$\n",
    "\n",
    " - Principle 3: States $|u\\rangle$ and $|d\\rangle$ are orthogonal to each other. This can be expressed as \n",
    " \n",
    "$$\\langle{u}|d\\rangle = 0$$\n",
    " \n",
    "We can write in matrix form:\n",
    "\n",
    "\n",
    "$$\\begin{pmatrix}(\\sigma_z)_{11} & (\\sigma_z)_{12}\\\\(\\sigma_z)_{21} & (\\sigma_z)_{22}\\end{pmatrix}\\begin{pmatrix}1\\\\0\\end{pmatrix}=\\begin{pmatrix}1\\\\0\\end{pmatrix}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\begin{pmatrix}(\\sigma_z)_{11} & (\\sigma_z)_{12}\\\\(\\sigma_z)_{21} & (\\sigma_z)_{22}\\end{pmatrix}\\begin{pmatrix}1\\\\0\\end{pmatrix}=-\\begin{pmatrix}0\\\\1\\end{pmatrix}$$\n",
    "\n",
    "There is only one matrix that satisfies these equations.\n",
    "\n",
    "\n",
    "$$\\begin{pmatrix}(\\sigma_z)_{11} & (\\sigma_z)_{12}\\\\(\\sigma_z)_{21} & (\\sigma_z)_{22}\\end{pmatrix}=\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}$$\n",
    "\n",
    "or, more cocisely,\n",
    "\n",
    "$$\\sigma_z=\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}$$\n",
    "\n",
    "In the similar fashion, we can work out following -\n",
    "\n",
    "$$\\sigma_x=\\begin{pmatrix}0&1\\\\1&0\\end{pmatrix}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\\sigma_y=\\begin{pmatrix}0&-i\\\\i&0\\end{pmatrix}$$\n",
    "\n",
    "These three matrices, $\\sigma_x$, $\\sigma_y$ and $\\sigma_z$, are famous *Pauli matrices*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d50841",
   "metadata": {},
   "source": [
    "### 3.5 A Common Misconception\n",
    "\n",
    "It is very easy to misunderstand the correspondence between operators and measurements. Here's what is true about operation in QM:\n",
    "\n",
    "\n",
    " 1. Operators are thing we use to calculate eigenvalues and eigenvectors. \n",
    " \n",
    " 2. Operators act on state-vectors (which are abstract mathematical objects), not on actual physical systems.\n",
    " \n",
    " 3. When an operator acts on a state-vector, it produces a new state-vector. \n",
    " \n",
    " It is often thought that measuring an observable is the same as operating with the corresponding operator on the state. For example, suppose we are interested in measuring an observable $\\text{L}$. The measurement is some kind of operation that the apparatus does to the system, but that operation is no way the same as acting on the state with the operator $\\text{L}$. For example, if the state of the system before we do the measurement is $|A\\rangle$, it is not correct to say that the measurement $\\text{L}$ changes the state to $\\text{L}|A\\rangle$. \n",
    " \n",
    "To explain better, recall that\n",
    "\n",
    "$$\\sigma_z|u\\rangle =|u\\rangle$$ \n",
    "\n",
    "$$\\sigma_z|d\\rangle = -|d\\rangle$$\n",
    "\n",
    "In these situations, there is no trap because $|u\\rangle$ and $|d\\rangle$ are eigenvectors of $\\sigma_z$. If the system was prepared in, say, the $|d\\rangle$ state, a measurement will definitely give the result $-1$, and the $\\sigma_z$ operator transforms the prepared state into the corresponding post-measurement state, $-|d\\rangle$. The state $-|d\\rangle$ is the same as $|d\\rangle$ except for a multiplicative constant, so the two states are really the same. \n",
    "\n",
    "But now let's see the action of $\\sigma_z$ on the prepared state $|r\\rangle$. We know that\n",
    "\n",
    "$$|r\\rangle=\\frac{1}{\\sqrt{2}}|u\\rangle +\\frac{1}{\\sqrt{2}}|d\\rangle$$\n",
    "\n",
    "Acting on this state-vector with $\\sigma_z$ gives the result\n",
    "\n",
    "$$\\sigma_z|r\\rangle=\\frac{1}{\\sqrt{2}}\\sigma_z|u\\rangle +\\frac{1}{\\sqrt{2}}\\sigma_z|d\\rangle$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\sigma_z|r\\rangle=\\frac{1}{\\sqrt{2}}|u\\rangle -\\frac{1}{\\sqrt{2}}|d\\rangle$$\n",
    "\n",
    "Despite what you might think, the state-vector on the right-hand side of above equation is definitely not the state that would result from a measurement of $\\sigma_z$. That measurement result would be either $+1$, leaving the system in state $|u\\rangle$ or $-1$, leaving the state in $|d\\rangle$. Neither of these results would leave the system state-vector in the superposition represented by the said equation. More on that in later chapters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac3215",
   "metadata": {},
   "source": [
    "### 3-Vector Operators Revisited\n",
    "\n",
    "We already know about ordinary 3-D vectors. We've also encountered state-vectors. Since spin operators ($\\sigma_x$, $\\sigma_y$ and $\\sigma_z$) behave much like vectors, we can treat them like vectors. \n",
    "\n",
    "We measure spin components by orienting the apparatus $\\text{A}$ along any one of the three axes and then activating it. But then why not orient $\\text{A}$ along *any* axis and measure the component of $\\sigma$ along that axis? In other words, take any unit 3-vector $\\hat{n}$ with components $n_x$, $n_y$ and $n_z$, and orient the apparatus $\\text{A}$ with its arrow along $\\hat{n}$. Activating $\\text{A}$ would then measure the components $\\sigma$ along the axis $\\hat{n}$. There must be an operator that corresponds to this measurable quantity. \n",
    "\n",
    "If we assume $\\sigma$ a 3-vector, then the component of $\\sigma$ along $\\hat{n}$ is nothing but the ordinary dot product of $\\sigma$ and $\\hat{n}$. Meaning\n",
    "\n",
    "$$\\sigma_n=\\vec{\\sigma}.\\hat{n}$$\n",
    "\n",
    "or, in expanded form,\n",
    "\n",
    "$$\\sigma_n= \\sigma_xn_x +\\sigma_yn_y+\\sigma_zn_z$$\n",
    "\n",
    "Note that, unlike usual dot pruducts, the result of dot product here is not a scalar value but a matrix. Also keep in mind that the components of $\\hat{n}$ are just numbers. They themselves are not operators. To be more concrete, we can write above eq as:\n",
    "\n",
    "\n",
    "$$\\sigma_n=n_x\\begin{pmatrix}0&1\\\\1&0\\end{pmatrix}+n_y\\begin{pmatrix}0&-i\\\\i&0\\end{pmatrix}+n_z\\begin{pmatrix}1&0\\\\0&-1\\end{pmatrix}$$\n",
    "\n",
    "Or even more explicitly, we can combine these three terms into a single matrix:\n",
    "\n",
    "$$\\sigma_n=\\begin{pmatrix}n_z&(n_x-in_y)\\\\(n_x+in_y)&-n_z\\end{pmatrix}$$\n",
    "\n",
    "Once we have eigenvectors and eigenvalues of $\\sigma_n$, we will know the possible outcomes of a measurement along the direction of $\\hat{n}$. And we will also be able to calculate probabilities for those outcomes. In other words, we will have a complete picture of spin measurements in three-dimensional space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e06539d",
   "metadata": {},
   "source": [
    "### Reaping the Results\n",
    "\n",
    "We're now positioned to make some real calculations. Let's look at the special case where $\\hat{n}$ lies in the *x-z* plane, which is the plane of this page. Since $\\hat{n}$ is a unit vector, we can write\n",
    "\n",
    "$$n_z=cos\\ \\theta$$\n",
    "$$n_x=sin\\ \\theta$$\n",
    "$$n_y=0$$,\n",
    "\n",
    "where $\\theta$ is the angle between the $z$ axis and the $\\hat{n}$ axis. Now, using the last eq from last section, we can write\n",
    "\n",
    "$$\\sigma_n=\\begin{pmatrix}cos\\ \\theta&sin\\ \\theta\\\\sin\\ \\theta&-cos\\ \\theta\\end{pmatrix}$$\n",
    "\n",
    "Note- solve the Ex 3.3 to better understand following results.\n",
    "\n",
    "Here are the results:\n",
    "\n",
    "$$\\lambda_1=1 $$\n",
    "\n",
    "$$|\\lambda_1\\rangle=\\begin{pmatrix}cos\\frac{\\theta}{2}\\\\sin\\frac{\\theta}{2}\\end{pmatrix}$$\n",
    "\n",
    "\n",
    "and\n",
    "\n",
    "$$\\lambda_2=-1 $$\n",
    "\n",
    "$$|\\lambda_2\\rangle=\\begin{pmatrix}-sin\\frac{\\theta}{2}\\\\cos\\frac{\\theta}{2}\\end{pmatrix}$$\n",
    "\n",
    "\n",
    "Notice some important facts. First, the two eigenvalues are again $+1$ and $-1$. This should come as no surprise: the apparatus $\\text{A}$ can only give one of these two results no matter which way it points. The second fact is that the two eigenvectors are orthogonal.\n",
    "\n",
    "We are now ready to make an experimental prediction. Suppose apparatus initially points along the $z$ axis and that we prepare a spin in the *up* state $|u\\rangle$. Then we rotate apparatus so that it lies along the $\\hat{n}$ axis. What is the probability of observing $\\sigma_n=+1$? According to principle 4, and using the row and column expansions of $\\langle{u}|$ and $|\\lambda_1\\rangle$, the answer is:\n",
    "\n",
    "$$P(+1)=|\\langle{u}|\\lambda_1\\rangle|^2=cos^2\\frac{\\theta}{2}$$.\n",
    "\n",
    "Similarily for the same setup,\n",
    "\n",
    "$$P(-1)=|\\langle{u}|\\lambda_2\\rangle|^2=sin^2\\frac{\\theta}{2}$$.\n",
    "\n",
    "\n",
    "When introducing spins, we made the claim that if we prepare a large number of them in the *up* state and then measure their component along $\\hat{n}$, at angle $\\theta$ to the *z* axis, then the average value of the measured results would be $cos\\ \\theta$-the same result we would get for a simple 3-vector in classical physics.\n",
    "\n",
    "Unfortunately, we need to cheat a little by using a equation that we will explain later. This is the equation that tells us how to calculate the average value (also called expectation value) of a measurement. Here it is:\n",
    "\n",
    "$$\\langle\\text{L}\\rangle=\\sum\\limits_{i}\\lambda_iP(\\lambda_i)$$\n",
    "\n",
    "Above eq is just a standard formula for an average value and this is not unique to QM.\n",
    "\n",
    "To calculate the expectation value of a measurement corresponding to the operator $\\text{L}$, we multiply each eigenvalue by its probability, and then sum the results. The operator we're looking at now is just $\\sigma_n$, and we already know all the values. We can do\n",
    "\n",
    "$$\\langle\\sigma_n\\rangle=(+1)cos^2\\frac{\\theta}{2}+(-1)sin^2\\frac{\\theta}{2}$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\langle\\sigma_n\\rangle=cos^2\\frac{\\theta}{2}-sin^2\\frac{\\theta}{2}$$\n",
    "\n",
    "Using trigonometry, we have\n",
    "\n",
    "$$\\langle\\sigma_n\\rangle=cos\\ \\theta$$\n",
    "\n",
    "Which agrees perfectly with experiment. \n",
    "\n",
    "We can do this for a slightly more general problem. So far we were working on *x-z* plane meaning $n_y=0$. Now we can rotate apparatus to an arbitrary direction in space, meaning now $n_y\\neq0$.\n",
    "\n",
    "**Note** some part skipped. Image to be inserted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f657602",
   "metadata": {},
   "source": [
    "### 3.8 The Spin-Polarization Principle\n",
    "\n",
    "There is an important theorem that you can try to prove.\n",
    "\n",
    "**The Spin-Polarization Principle:** *Any state of a single spin is an eigenvector of some component of the spin.*\n",
    "\n",
    "In other words, given any state\n",
    "\n",
    "$$|A\\rangle=\\alpha_u|u\\rangle  +\\alpha_d|d\\rangle$$\n",
    "\n",
    "there exists some direction $\\hat{n}$, such that\n",
    "\n",
    "$$\\vec{\\sigma}.\\vec{n}\\ |A\\rangle =|A\\rangle$$\n",
    "\n",
    "This means that for any spin state, there is some orientation of the apparatus $\\text{A}$ such that $\\text{A}$ will register $+1$ when it acts. In physics language, we say that the states of a spin are characterized by a *polarization vector*, and along that polarization vector the component of spin is predictably $+1$, assuming of coursethat you know the state vector. \n",
    "\n",
    "An interesting consequence of this theorem is that there is no state for which the expectation values of all three components of spin are zero. There is a quantitative way to express this. Consider the expectation value of $\\vec{\\sigma}.\\vec{n}\\$ (with eigenvalue +1), it follows that the expectation value can be expressed as \n",
    "\n",
    "$$\\vec{\\sigma}.\\vec{n} =1$$\n",
    "\n",
    "On the other hand, the expectation value of a the perpendicular components of $\\sigma$ are zero in the state $|A\\rangle$. It follows that squares of the expectation values of all three components of $\\sigma$ sum to $1$. Moreover, this is true for any state:\n",
    "\n",
    "$$\\langle\\sigma_x\\rangle^$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156adcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b727929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8518c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "=+"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
